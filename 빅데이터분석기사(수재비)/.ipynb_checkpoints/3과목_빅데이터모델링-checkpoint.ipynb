{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d00c138",
   "metadata": {},
   "source": [
    "# 분석 모형 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b214a",
   "metadata": {},
   "source": [
    "## 분석 절차 수립 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda23df4",
   "metadata": {},
   "source": [
    "### 분석 모형 선정 \n",
    "\n",
    "1. 통계기반 분석 모형 선정 \n",
    "    \n",
    "    - 통계분석 : 불확실한 상황에서 객관적인 의사결정을 수행하기 위해 데이터를 수집하고, 처리, 분류, 분석 및 해석하는 일련의 체계\n",
    "    \n",
    "    - 기술통계 \n",
    "        - 수집된 데이터를 확률, 통계적으로 정리, 요약하는 기초적인 통계\n",
    "        - 데이터에 대한 대략적인 통계적 수치를 계산하고 도출\n",
    "        - 그래프를 활용하여 데이터를 파악\n",
    "        - 분석 초기 단계에서 데이터 분포의 특징 파악\n",
    "    \n",
    "    - 상관분석\n",
    "        - 두 개 이상의 변수 간에 존재하는 상호 연관성의 정도를 측정하여 분석하는 방법\n",
    "        - 단순상관 분석 : 두 변수 사이의 연관 관계 분석\n",
    "        - 다중상관 분석 : 셋 또는 그 이상의 변수들 사이의 연관 정도를 분석\n",
    "        - 변수 간의 상관 분석 : 데이터 속성에 따라서 수치적, 명목적, 순서적 데이터 등 을 가지는 변수 간의 상관분석\n",
    "    \n",
    "    - 회귀분석\n",
    "        - 하나 이상의 독립변수들의 종속변수에 미치는 영향을 추정할 수 있는 통계 기법\n",
    "        - 단순선형 회귀 : 독립변수가 1개, 종속변수와의 관계가 직선\n",
    "        - 다중선형 회귀 : 독립변수가 K개, 종속변수와의 관계가 선형\n",
    "        - 다항 회귀 : 독립변수와 종속변수와의 관계가 1차 함수 이상인 관계\n",
    "        - 곡선 회귀 : 독립변수가 1개이며 종속변수와의 관계가 직선\n",
    "        - 로지스틱 회귀 : 종속변수가 범주형인 경우 적용 \n",
    "        - 비선형 회귀 : 회귀식의 모양이 선형관계로 이뤄져 있지 않은 모형\n",
    "    \n",
    "    - 분산분석\n",
    "        - 두 개 이상의 집단 간 비교를 수행하고자 할 때 집단 내의 분선의 비교로 얻은 분포를 이용하여 가설검정을 수행\n",
    "        - 복수의 집단을 비교할 때 분산을 계산함으로써 집단 간에 통계적인 차이를 판정하는 분석 \n",
    "    \n",
    "    - 주성분분석\n",
    "        - 많은 변수의 분산 방식의 패턴을 간결하게 표현하는 주성분 변수를 원래 변수의 선형 결합으로 추출하는 통계 기법\n",
    "    \n",
    "    - 판별분석\n",
    "        - 집단에 대한 정보로부터 집단을 구별할 수 있는 판별 규칙을 만들고, 다변량 기법으로 조사된 집단에 대한 정보를 활용하여 새로운 개체가 어떤 집단인지를 탐색하는 통계기법\n",
    "        \n",
    "   \n",
    "2. 데이터 마이닝 기반 분석 모형 선정\n",
    "    \n",
    "    - 데이터 마이닝 : 대용량 데이터로부터 데이터 내에 존재하는 패턴, 관계 혹은 규칙 등을 탐색하고 통계적인 기법을 활용하여 모델화 하여 정보를 추출\n",
    "    \n",
    "    - 분류 모델 \n",
    "        - 범주형 변수 혹은 이산형 변수등의 범주를 예측하는 것\n",
    "        - 사전에 정해진 그룹이나 범주 중의 하나로 분류하는 모델 \n",
    "    \n",
    "    - 예측 모델\n",
    "        - 범주형 및 수치형 등의 과거 데이터로부터 특성을 분석하여 다른 데이터의 결과값을 예측하는 기법\n",
    "        - 회귀분석 : 관찰된 연속형 변수들에 대해 두 변수 사이의 모형을 구한 뒤 적합도를 측정해 내는 분석 기법\n",
    "        - 의사결정나무 : 의사결정 규칙을 트리구조로 도표화하여 분류와 예측을 수행하는 분성 방법\n",
    "        - 시계열 분석 : 연도별, 분기별, 월별 등 시계열로 관측되는 자료를 분석하여 미래를 예측\n",
    "        - 인공신경망\n",
    "    \n",
    "    - 군집화 모델 \n",
    "        - 이질적인 집단을 몇개의 동질적인 소집단으로 세분화 하는작업\n",
    "        - 군집들 사이의 관계를 분석하는 다변량 분석 기법\n",
    "        - 계층적 방법\n",
    "            - 병합적(응집분석) 방법 : 유사한 소집단들을 합쳐 새로운 소집단을 구성 \n",
    "            - 분할적(분할분석) 방법 : 전체 집단에서 유사성이 떨어지는 객체들을 분리하는 방법 \n",
    "        - 비 계층적 방법\n",
    "            - K-means Clustering\n",
    "    \n",
    "    - 연관규칙 모델 \n",
    "        - 데이터에 숨어 있으면서 동시에 발생하는 사건 혹은 항목 간의 규칙을 수치화하는 기법\n",
    "        - 장바구니 분석, 마케팅에서 활용된다\n",
    "        \n",
    "        \n",
    "3. 머신러닝 기반 분석 모형 선정\n",
    "    \n",
    "    - 지도 학습(Supervised Learning)\n",
    "        - 정답인 레이블(Label)이 포함되어 있는 학습 데이터를 통해 컴퓨터를 학습시키는 방법\n",
    "        - 설명변수와 목적변수 간의 관계성을 표현해내거나 미래 관측을 예측해내는 것 \n",
    "        - 로지스틱 회귀 : 반응변수가 범주형인 경우 적용되는 회귀분석 모형\n",
    "        - 인공신경망 분석 : 인간의 뉴런구조 모방\n",
    "        - 의사결정나무 \n",
    "        - 서포트 벡신 머신 : 데이터를 초평면 중에서 데이터들과 거리가 가장 먼 초 평면을 선택하여 분리하는 지도 학습\n",
    "        - 랜덤 포레스트 : 의사결정나무의 배깅과 부스팅보다 더 많은 무작위성을 주어 선형 결합\n",
    "        - 감성 분석 \n",
    "        \n",
    "    - 비지도 학습(Unsupervised Learning)\n",
    "        - 입력 데이터에 대한 정답인 레이블(Label)이 없는 상태에서 훈련 데이터를 통해 학습시키는 방법\n",
    "        - 현상의 설명이나 특징 도출, 패턴 도출 등의 문제에 사용\n",
    "        - 사전정보가 없는 상태에서 유용한 정보나 패턴을 탐색적으로 발견하고자 하는 데이터 마이닝의 성격과 유사 \n",
    "        - 군집화, 인공신경망, 딥러닝이 적용 \n",
    "        \n",
    "    - 강화 학습(Reinforcement Learning)\n",
    "        - 선택 가능한 행동 중 보상을 최대화하는 행동 혹은 행동 순서를 선택하는 학습 방법\n",
    "        - 행동에 대한 반응에 따라 보상이 주어진다\n",
    "        - 보상을 최대한 많이 얻도록 하는 행동을 유도하도록 학습을 진행한다\n",
    "        \n",
    "        \n",
    "4. 변수에 따른 분석 기법 선정 \n",
    "\n",
    "    - 변수의 개수에 따른 분석기법 \n",
    "        - 단일변수 분석(Univariate Analysis) : 연속형 변수는 히스토그램이나 박스플롯을 사용하여 평균, 최빈수, 중위수 등 과 함께 분포 확인\n",
    "        - 이변수 분석 : 변수의 유형에 따라 적절한 시각화 분석 방법 선택\n",
    "        - 다변수 분석 : 범주형 변수가 하나 이상 포함된 경우 변수를 범주에 따라 쪼갠 후, 단변수나 이변수 분석 방법에 따라 분석\n",
    "        \n",
    "    - 데이터 유형에 따른 분석 기법 \n",
    "    \n",
    "        | 독립변수/종속변수 | 연속형 변수 | 이산형/범주형 변수 | \n",
    "        | : --- : | : --- : | : --- : | \n",
    "        | 연속형 변수 | 회귀분석, 인공신경망 모델, K-최근접 이웃기법 | 로지스틱 회귀분석, 판별분석, K-최근접 이웃기법 | \n",
    "        | 이산형/범주형 변수 | 회귀분석, 인공신경망 모델, 의사결정나무(회귀) | 인공신경망 모델, 의사결정나무(분류), 로지스틱 회귀분석 |     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55662a4d",
   "metadata": {},
   "source": [
    "### 분석 모형 정의  \n",
    "\n",
    "1. 분석 모형 정의 : 분석 모형을 선정하고 모델에 적합한 변수를 선택하여 모형의 사양을 작성하는 기법\n",
    "\n",
    "\n",
    "2. 매개변수 \n",
    "    - 모델 내부에서 확인이 가능한 변수로 데이터를 통해서 산출이 가능한 값\n",
    "    - 모델에 의해 요구되어지는 값들\n",
    "    - 매개변수가 모델의 성능을 결정\n",
    "    - 가중치, 서포트 벡터, 결정계수\n",
    "    \n",
    "\n",
    "3. 초매개변수\n",
    "    - 모델에서 외적인 요소로 데이터 분석을 통해 얻어지는 값이 아닌 사용자가 직접 설정해주는 값\n",
    "    - 모델의 매개변수값을 측정하기 위해 알고리즘 구현과정에서 사용 \n",
    "    - 학습률(Learning Rate), 깊이(Depth), 은닉층의 개수, KNN에서 K의 개수 \n",
    "    \n",
    "    \n",
    "4. 분석 모형 정의 고려사항 \n",
    "    - 과소적합 : 적정 수준의 학습이 부족하여 실제 성능이 떨어지는 현상 \n",
    "    - 과대적합 : 학습 데이터에 대한 성능은 좋으나 실제 데이터에 성능이 떨어지는 현상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ff2a3",
   "metadata": {},
   "source": [
    "### 분석 모형 구축 절차 \n",
    "\n",
    "1. 요건 정의 : 분석과제 정의를 통해 도출된 내용을 요건 정의로 구체화하는 과정 \n",
    "    - 분석요건 도출 \n",
    "        - 분석요건을 추출, 분석, 명세화하고 종합적으로 적합성을 검토\n",
    "        - 데이터 분석 업무의 배경, 주요 이슈, 기대효과, 제약사항을 사전에 정의함\n",
    "    \n",
    "    - 수행방안 설계 \n",
    "        - 탐색적 분석을 수행하여 분석 가능성을 검토\n",
    "        - 데이터베이스 접근 환경을 구축하고, 분석 대상 데이터의 존재 여부를 확인하는 등 기초 분석 수행 \n",
    "    \n",
    "    - 요건 확정 \n",
    "        - 수립된 기획안을 이해관계저와 공유하여 최종 요건을 확정\n",
    "       \n",
    "\n",
    "2. 모델링\n",
    "    - 모델링 마트 설계 및 구축\n",
    "        - 다양한 원천 데이터로부터 분석 대상 데이터 획득\n",
    "        - 탐색, 정제, 요약 등의 전처리르 통해 변수들을 식별\n",
    "        - 분석 대상 데이터를 적재해 모델 마트를 구축\n",
    "    \n",
    "    - 탐색적 분석과 유의 변수 도출\n",
    "        - 유의미한 변수를 파악하기 위해 목표값 별로 해당 변수의 분포된 값을 보고 차이가 큰지 파악\n",
    "        - 분석 모형 및 데이터의 유의성을 반복적으로 보정\n",
    "        - 최소한의 시간에 탐색적 분석을 완료하여 단위 분석에 대한 소요 시간을 추정\n",
    "     \n",
    "    - 모델링\n",
    "        - 업무 특성에 적합나 기법을 선택하거나 여러 모델링 기법을 결합해 적용 \n",
    "        - 시뮬레이션과 최적화를 결합해 적용 \n",
    "    \n",
    "    - 모델링 성능 평가 \n",
    "        - 정확도, 정밀도, 재현율, 향상도 등의 값으로 판단\n",
    "\n",
    "\n",
    "3. 검증 및 평가 \n",
    "    - 분석데이터를 훈련(60 ~ 80%)과 평가(20 ~ 40%) 데이터로 분리한 다음 검증 및 평가 \n",
    "    - 운영 상황에서 실제 테스트 \n",
    "        - 분석결과를 업무 프로세스에 가상으로 적용해 검증하는 실무 적용 직전의 활동 \n",
    "        - 테스트하기 위한 유사 운영환경을 구축\n",
    "        - 설계 절차에 따라 테스트하고 그 결과를 분석 \n",
    "    - 비즈니스 영향도 평가 : 투자 대비 효과 정량화 기법으로 비즈니스 영향도 평가\n",
    "\n",
    "\n",
    "4. 적용\n",
    "    - 운영 시스템에 적용과 자동화\n",
    "    - 주기적 리모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbbbd6c",
   "metadata": {},
   "source": [
    "## 분석 환경 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a013db",
   "metadata": {},
   "source": [
    "### 분석 도구 설정 \n",
    "\n",
    "1. R\n",
    "    - 통계 프로그래밍 언어인 S언어를 기반으로 만들어진 오픈 소스 프로그래밍\n",
    "    - 15,000개 이상의 패키지를 직접 추가하여 기능을 확장할 수 있음\n",
    "    - R Studio(IDE)\n",
    "    - Windows, Mac OS, Linux 등 다양한 OS 지원\n",
    "    \n",
    "    \n",
    "2. Python\n",
    "    - C언어 기반의 오픈 소스 프로그래밍 언어    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871adc3",
   "metadata": {},
   "source": [
    "### 데이터 분할 \n",
    "\n",
    "\n",
    "- 훈련 데이터와 검증 데이터는 학습 과정에서 사용하며, 평가 데이터는 학습 과정에 사용되지 않고 평가를 위해 사용됨\n",
    "- 학습이 완료된 모형에 대하여 한 번도 사용하지 않은 평가데이터 활용\n",
    "- 훈련데이터 : 60 ~ 80% vs 평가데이터 : 20 ~ 40% 활용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ca0854",
   "metadata": {},
   "source": [
    "# 분석 기법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf568254",
   "metadata": {},
   "source": [
    "## 분석 기법 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3262558",
   "metadata": {},
   "source": [
    "### 회귀 분석 \n",
    "\n",
    "1. 회귀분석 개념\n",
    "    - 독립변수와 종속변수 간에 선형적인 관계를 도출해서 종속변수를 예측하는 분석 기법\n",
    "    - 변수들 사이의 인과관계를 밝히고 모형을 적합(Fit)하여 관심 있는 변수를 예측하거나 추론하기 위한 분석 방법\n",
    "    \n",
    "\n",
    "2. 회귀 모형의 가정 \n",
    "    - 선형성 \n",
    "        - 독립변수와 종속변수가 선형적이어야 한다는 특성\n",
    "        - 독립변수의 변화에 따라 종속변수도 일정 크기로 변화\n",
    "        \n",
    "    - 독립성 \n",
    "        - 잔차와 독립변수의 값이 서로 독립적이어야 함\n",
    "        - 더빈-왓슨 검정을 통해 확인 가능\n",
    "        \n",
    "    - 등분산성\n",
    "        - 잔차의 분산이 독립변수와 무관하게 일정해야 함\n",
    "    \n",
    "    - 비상관성\n",
    "        - 관측치와 잔차는 서로 상관이 없어야 함\n",
    "        \n",
    "    - 정규성\n",
    "        - 잔차항이 정규분포의 형태를 이뤄야 함 \n",
    "        - Q-Q plot에서 직선의 형태를 띄어야 함\n",
    "        \n",
    "\n",
    "3. 회귀 모형 검증\n",
    "    - 회귀 모형이 통계적으로 유의미한가?\n",
    "        - F-통계량을 통해 확인\n",
    "        - 유의수준 5% 하에서 p-값이 0.05보다 작으면 통계적으로 유의미\n",
    "        \n",
    "    - 회귀계수들이 유의미한가?\n",
    "        - t-통계량을 통해 신뢰구간 확인\n",
    "        \n",
    "    - 회귀 모형이 얼마나 설명력을 갖는가? \n",
    "        - 회귀식 자체의 유의성을 확인\n",
    "        - 결정계수($R^2$)를 통해 판단\n",
    "        \n",
    "    - 회귀 모형이 데이터를 잘 적합하고 있는가?\n",
    "        - 잔차를 그래프로 그리고 회귀진단을 함\n",
    "        \n",
    "    - 데이터가 가정을 만족시키는가?\n",
    "        - 선형성, 독립성, 등분산성, 비상관성, 정규성 가정을 만족\n",
    "        \n",
    "        \n",
    "4. 단순 선형 회귀 분석\n",
    "    - 단순 선형 회귀식\n",
    "        - $Y = \\beta_0 + \\beta_1 X + \\epsilon$\n",
    "        - 회귀 모형 중에서 가장 단순한 모형\n",
    "        - 독립변수와 종속변수가 각각 한 개이며 오차항이 있는 선형관계로 이루어져 있음\n",
    "        \n",
    "    - 회귀계수 추정\n",
    "        - 최소제곱법을 사용하여 추정한다. \n",
    "        - 오차의 제곱 합이 최소가 되는 추세선이 가장 합리적인 추세선 \n",
    "        - $\\sum_{i=1}^{n}(y_i - (\\beta_0 + \\beta_1x_i))^2$\n",
    "        \n",
    "    - 회귀 분석의 검정\n",
    "        - 회귀 계수 검정 : 회귀계수 $\\beta_1$이 0이면 입력변수와 출력변수는 인과관계가 없음\n",
    "        - 결정계수 \n",
    "            - 결정계수($R^2$)는 전체 데이터를 회귀 모형이 얼마나 잘 설명하고 있는지를 보여주는 지표 \n",
    "            - $R^2 = \\frac{SSR}{SST} = \\frac{SSR}{SSR+SSE}$\n",
    "            - 전체 제곱합(SST) = $\\sum_{i=1}^{n}(y_i-\\overline{y})^2$\n",
    "            - 회귀 제곱합(SSR) = $\\sum_{i=1}^{n}(\\hat{y}-\\overline{y})^2$\n",
    "            - 오차 제곱합(SSE) = $\\sum_{i=1}^{n}(y_i-\\hat{y})^2$\n",
    "        - 회귀직선의 적합도 검토 : 결정계수를 통해 추정된 회귀식이 얼마나 타당한지 검토 \n",
    "        \n",
    "\n",
    "5. 다중 선형 회귀 분석 \n",
    "    - 다중 선형 회귀식\n",
    "        - $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k + \\epsilon$\n",
    "        \n",
    "    - 모형의 통계적 유의성\n",
    "        - 통계적 유의성은 F-통계량으로 확인한다. \n",
    "        - n은 표본의 개수, k는 변수의 개수\n",
    "        - 회귀 제곱 평균(MSR) = $MSR = \\frac{SSR}{k}$\n",
    "        - 잔차 제곱 평균(MSE) = $MSE = \\frac{SSE}{n-k-1}$\n",
    "        - 총 제곱 평균(MST) = $MST = \\frac{SST}{n-1}$\n",
    "        - $F = \\frac{MSR}{MSE}$\n",
    "        \n",
    "    - 회귀 분석의 검정 \n",
    "        - 회귀 계수 유의성 : 회귀 계수 유의성 검토와 동일하게 t-통계량을 확인\n",
    "        - 결정계수($R^2$) : 전체 데이터를 회귀 모형이 얼마나 잘 설명하고 있는 지를 보여주는 지표\n",
    "        - 수정된 결정계수($Adjusted R^2$) \n",
    "            - 결정계수는 독립변수의 수에 따라 증가하는 성질이 있음\n",
    "            - 이를 방지하기 위해 수정된 결정계수를 사용\n",
    "            - $R_a^2 = 1-(n-1)\\frac{MSE}{SST}$\n",
    "        - 모형의 적합성 : 잔차와 종속변수의 산점도로 확인\n",
    "        - 다중공선성 \n",
    "            - 설명변수들 사이에 선형 관계가 존재하면 회귀계수의 정확한 추정이 난해함\n",
    "            - 분산팽창요인(VIF), 상태지수를 통해 검사를 진행\n",
    "            - 다중공선성 문제가 발생하면 문제가 있는 변수를 제거하거나 주성분회귀, 능형 회귀를 적용하여 문제를 해결\n",
    "    \n",
    "    - 변수선택 방법\n",
    "        - 전진 선택법 : 상수 모형부터 시작해 중요하다고 생각되는 설명변수를 차례로 모형에 추가하는 방식\n",
    "        - 후진 소거법 : 독립ㅂ변수 후보 모두를 포함한 모형에서 출발해 제곱합을 기준으로 가장 적은 영향을 주는 변수부터 하나씩 제거하여 변수를 선택\n",
    "        - 단게적 방법 : 새롭게 추가된 변수에 기인해 기존 변수가 그 중요도가 악화될 때 해당 변수의 제거를 검토함\n",
    "        \n",
    "    - 벌점화된 선택기준 : 모형의 복잡도에 벌점을 주는 방식\n",
    "        - AIC(Akaike information Criterion)\n",
    "            - 실제 데이터의 분포와 모형이 예측하는 분포 사이의 차이를 나타내는 방법\n",
    "            - $AIC = -2ln(L) + 2p$ \n",
    "            - $-2ln(L)$ : 모형의 적합도, $2p$ : 매개변수 계수\n",
    "            - AIC값이 높다는 것은 모형의 적합도가 높다는 것을 의미\n",
    "            - 독립변수가 많은 모형, 즉 p가 증가할수록 AIC값이 증가하게 되므로 좋지 않은 모형이다\n",
    "        - BIC(Bayesian information Criterion)\n",
    "            - AIC의 단점은 표본이 클수록 부정확해진다 \n",
    "            - $BIC = -2ln(L) + pln(n)$\n",
    "            - AIC의 벌점은 표본 크기에 상관없이 일정하지만, BIC의 벌점은 표본 크기가 커질수록 커진다\n",
    "            - 표본의 크기가 커질수록 복잡한 모형을 더 강하게 처벌한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4748e578",
   "metadata": {},
   "source": [
    "### 로지스트 회귀 분석 \n",
    "\n",
    "1. 로지스틱 회귀 분석 \n",
    "    - 독립변수가 수치형이고 반응변수(종속변수)가 범주형(이산형)인 경우 적용되는 회귀 분석 모형 \n",
    "    - 반응변수의 각 범주에 속할 확률이 얼마인지를 추정하여 기준치에 따라 분류하는 모형 \n",
    "    - $ Y = \\frac{exp(\\beta_0 + \\beta_1 X_1 + ... \\beta_k X_k}{1 + exp(\\beta_0 + \\beta_1 X_1 + ... \\beta_k X_k}$\n",
    "    \n",
    "2. 로지스틱 회귀 분석의 원리 \n",
    "\n",
    "- 원리 : 독립변수가 어느 숫자이든 상관없이 종속변수의 결과값이 항상 범위 [0,1] 사이에 있도록 한다\n",
    "\n",
    "- 오즈(Odds) \n",
    "    - 특정 사건이 발생할 확률과 그 사건이 발생하지 않을 확률의 비 \n",
    "    - $Odds(p) = \\frac{p}{1-p}$\n",
    "    \n",
    "- 로짓(Logit) 변환\n",
    "    - 오즈에 로그를 취한 함수로서 입력값의 범위가 [0,1]일 때 범위를 $(-\\infty ~ +\\infty)로 조정한다$\n",
    "    - $Logit(p) = log\\frac{p}{1-p} = log odds(p)$\n",
    "   \n",
    "- 시그모이드(Sigmoid) 함수\n",
    "    - 로짓함수에 역함수를 취하면 x의 값이 $(-\\infty ~ +\\infty)$일 때, y 값은 [0, 1]의 값을 가지게 된다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f80d8",
   "metadata": {},
   "source": [
    "### 의사 결정 나무 \n",
    "\n",
    "1. 의사결정나무(Decision Tree) \n",
    "    - 의사결정 규칙을 나무(Tree)구조로 나타내어 전체 자료를 몇 개의 소집단으로 분류하거나 예측하는 분석\n",
    "    - 분석의 대상을 분류함수를 사용하여 의사결정 규칙으로 이루어진 나무 모형을 만듬\n",
    "    - 의사결정 문제를 시각화해서 의사결정이 이루어지는 시점과 성과 파악을 쉽게 해준다 \n",
    "    \n",
    "    \n",
    "2. 의사결정나무의 구성요소\n",
    "    - 부모마디(Parent Node) : 주어진 마디의 상위에 있는 마디 \n",
    "    - 자식마디(Child Node) : 하나의 마디로부터 분리되어 나간 2개 이상의 마디들\n",
    "    - 뿌리마디(Root Node) : 시작되는 마디로 전체 자료를 포함\n",
    "    - 끝마디(Terminal Node) : 잎(Leaft)노드, 자식마디가 없는 마디 \n",
    "    - 중간마디(Internal Node) : 부모 마디와 자식 마디가 모두 있는 마디 \n",
    "    - 가치(Branch) : 뿌리 마디로부터 끝마디까지 연결된 마디들 \n",
    "    - 깊이(Depth) : 뿌리 마디로부터 끝마디까지 중간 마디들의 수 \n",
    "    \n",
    "    \n",
    "3. 의사결정나무 분석 과정 \n",
    "    - 의사결정나무 성장 : 종속변수와 관계가 있는 독립변수를 추가하고, 분석의 목적과 자료 구조에 따라서 적절한 분리규칙을 찾아 나무를 성장시키는 과정으로, 정지 규칙을 충족시키면 중단\n",
    "    - 가지치기 : 분리 오류를 크게 할 위험이 높거나, 부적절한 추론 규칙을 가지고 있는 가지(Branch) 또는 불필요한 가지를 제거하는 단계 \n",
    "    - 타당성 평가 : 이익 도표, 위험 도표 또는 평가 데이터를 이용하여 교차 타당성을 이용한 평가 수행 단계 \n",
    "    - 해석 및 예측 : 구축된 의사결정나무를 해석하고 데이터의 분류 및 예측에 활용하는 단계 \n",
    "    \n",
    "    \n",
    "4. 의사결정나무의 성장 \n",
    "\n",
    "    - 분류 규칙(Splitting Rule) \n",
    "        - 분리변수(Split Variable)가 연속형인 경우, $ A = x_i \\leq s $\n",
    "        - 분리변수가 범주형인 경우, $ A = [1, 2, 3], A^c = [4] $\n",
    "        - 불순도 감소량을 가장 크게 하는 분할\n",
    "        - 최적 분리 기준에 의한 분할을 찾은 후 각 분할에 대해서도 동일한 과정 반복 \n",
    "\n",
    "    - 분리 기준(Splitting Criterion) \n",
    "        - 목표변수의 분포를 구별하는 정도를 순수도, 불순도에 의해서 측정한다\n",
    "        - 부모 마디의 순수도에 비해 자식 마디들의 순수도가 증가하도록 형성 \n",
    "        - 이산형 종속변수에 사용되는 분리 기준\n",
    "            - 카이제곱 통계량의 p-value : p-value가 가장 작은 예측변수의 최적 분리를 통해 자식 마디 형성\n",
    "            - 지니 지수(Gini index) : 지니 지수를 가장 감소시켜주는 예측변수의 최적 분리를 통해 형성 \n",
    "            - 엔트로피 지수(Entropy index) : 엔트로피 지수가 가장 낮은 예측변수의 최적 분리를 통해 형성 \n",
    "        - 연속형 종속변수에 사용되는 분리 기준\n",
    "            - F-통계량 : p-value 값이 가장 작은 예측변수의 최적 분리를 통해 형성\n",
    "            - 분산의 감소량 : 분산의 감소량을 최대화하는 기준의 최적 분리를 통해 형성\n",
    "\n",
    "    - 정지규칙\n",
    "        - 더 이상 분리가 일어나지 않고 현재의 마디가 끝마디가 되도록 하는 규칙\n",
    "        - 깊이(Depth), 레코드 수의 최소 개수를 지정 \n",
    "\n",
    "    - 가지 나무치기(Prunning)\n",
    "        - 너무 큰 나무 모형은 과대 적합, 너무 작은 나무 모형은 과속 적합 문제를 야기 \n",
    "        - 최적의 나무 크기를 비용-복잡도 가지치기를 활용하여 가지치기를 진행 \n",
    "    \n",
    "    \n",
    "5. 불순도 척도 \n",
    "\n",
    "    - 카이제곱 통계량 \n",
    "        - $ \\chi^2 = \\sum_{i=1}^{k}\\frac{(O_i - E_i)^2}{E_i}$\n",
    "        - 기대도수 = 열의 합게 X 합의 합계 / 전체 합계 \n",
    "\n",
    "    - 지니 지수\n",
    "        - $Gini(T) = 1 - \\sum_{i=1}^{k}P_{i}^2$\n",
    "        - 노드의 불순도를 나태나는 값 \n",
    "\n",
    "    - 엔트로피 지수 \n",
    "        - $Entropy(T) = -(\\sum_{i=1}^{k}P_{i}log_{2}P_i)$\n",
    "        - 무질서 정도에 대한 척도 \n",
    "\n",
    "\n",
    "6. 의사결정나무 알고리즘 \n",
    "    - CART(이진분할)\n",
    "        - 독립변수를 이분화하는 과정을 반복하여 이진트리 형태로 분류를 수행하는 알고리즘\n",
    "        - 가장 성취도가 좋은 변수 및 수준을 찾는 것에 중점\n",
    "        \n",
    "    - C4.5 or C5.0\n",
    "        - 가지치기를 사용할 때 학습자료를 사용하는 알고리즘\n",
    "        - 종속변수가 이산형이어야 함\n",
    "        - 엔트로피 지수를 사용 \n",
    "        - 각 마디에서 다지 분리가 가능하며 범주형 독립변수에 대해서는 범주 수만큼 분리가 일어남 \n",
    "        \n",
    "    - CHAD(다지분할)\n",
    "        - AID를 발전시킨 알고리즘\n",
    "        - 적당한 크기에서 성장을 중시하며 독립변수가 이산형이어야 함\n",
    "        - 카이제곱 통계량을 사용 \n",
    " \n",
    "    - QUEST\n",
    "        - 범주의 개수가 많은 범주형 변수로의 편향이 심각한 CADT의 문제점을 개선한 알고리즘\n",
    "        - 변수 선택 편향이 거의 없음\n",
    "        - 카이제곱 통계량을 사용\n",
    "        - 이진 분리를 사용 \n",
    "\n",
    "\n",
    "7. 의사결정나무 활용 \n",
    "    - 활용\n",
    "        - 분류 : 여러 예측변수들에 근거해서 관측 개체의 목표변수 범주를 몇 개의 등급으로 분류하고자 하는 경우에 활용\n",
    "        - 예측 : 자료에서 규칙을 찾아내고 미래의 사건을 예측함\n",
    "        - 차원축소 및 변수 선택 : 독립변수 중에서 종속변수에 큰 영향을 미치는 변수들을 구분할 때 사용 \n",
    "        - 교호작용 및 효과의 파악 : 독립변수들을 결합해서 종속변수에 작용하는 규칙을 파악하고자 하는 경우에 사용 \n",
    "        \n",
    "    - 장점\n",
    "         - 해석의 용이 \n",
    "         - 상호작용 효과의 해석가능\n",
    "         - 비모수적 모형\n",
    "         - 유연성과 정확도가 높음\n",
    "    - 단점\n",
    "        - 비연속성\n",
    "        - 선형성 또는 주 효과의 결여 \n",
    "        - 비안정성 \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247f0b2",
   "metadata": {},
   "source": [
    "### 인공신경망 \n",
    "\n",
    "1) 인공신경망\n",
    "\n",
    "-   사람 두뇌의 신경세포인 뉴런이 전기신호를 전달하는 모습을 모방한 기계학습의 모델\n",
    "-   입력값을 받아서 출력값을 만들기 위해 활성화 함수를 이용\n",
    "\n",
    "2) 인공신경망 역사\n",
    "\n",
    "-   1세대(1943~1986)\n",
    "    -   퍼셉트론이라는 선형 분류가 가능한 순방향 신경망을 제안\n",
    "    -   XOR 선형 분리 불가 문제 발생\n",
    "-   2세대(1986~2006)\n",
    "    -   다층 퍼셉트론과 역전파 알고리즘의 등장\n",
    "    -   은닉층을 통해 XOR문제 해결\n",
    "-   3세대(2006~)\n",
    "    -   과적합 문제 및 기울기 소실 문제 해결\n",
    "\n",
    "**순방향 신경망(Feed Forward Neural Network)**  \n",
    "입력데이터가 입력층 -> 은닉층 -> 출력층의 순서로 전파되어 판별함수 값으로 변환되는 신경망\n",
    "\n",
    "**다층 퍼셉트론(Multi-Layer Perceptrons)**  \n",
    "입력층과 출력층 사이에 하나 이상의 은닉층을 두어 비선형적으로 분리되는 데이터 대해 학습이 가능한 퍼셉트론\n",
    "\n",
    "**역전파 알고리즘(Back Propagation Algorithm)**  \n",
    "역방향으로 가중치 갱신을 통해 오차를 최소화키도록 학습시키는 알고리즘\n",
    "\n",
    "**은닉층(Hidden Layer)**  \n",
    "인공신경망에서 입력층과 출력층 사이에 위치하여 내부적으로 동작하는 계층\n",
    "\n",
    "**기울기 소실문제(Gradient Vanishing Problem)**  \n",
    "오차 역전파에서 계산 결과와 정답과의 오차를 통해 가중치를 수정하는데, 입력층으로 갈수록 기울기가 사라져 가중치들이 업데이트 되지 않아 최적의 모델을 찾을 수 없는 문제. 계층을 이동할 때마다 노드의 활성화 함수의 미분 값을 곱하게 되는데, 시그모이드 함수는 미분값이 0~0.25로 입력층에 갈수록 0에 가까워져 기울가 사라져 가중치가 적용되지 않음\n",
    "\n",
    "**활성화 함수(Activation Function)**  \n",
    "인공신경망 모델에서 입력 신호의 총합을 출력 신호로 변환하는 함수로, 입력 받은 신호를 얼마나 출력할지 결정하고, 다음 단계에서 출력된 신호의 활성화 여부를 결정하는 함수\n",
    "\n",
    "3) 인공신경망의 구조\n",
    "\n",
    "-   퍼셉트론\n",
    "    -   입력층, 출력층으로 구성한 인공신경망 모델\n",
    "    -   입력값, 가중치, 순 입력함수, 활성화 함수, 예측값(출력값)\n",
    "    -   $\\sum\\_{i=1}^{n}(w_j x_j) $\n",
    "    -   순 입력함수 값을 활성화 함수의 임곗값과 비교하여 예측값을 출력\n",
    "    -   XOR의 선형 분리 문제점 존재  \n",
    "        [##_Image|kage@TyAv0/btrtIfaNjQZ/Wfu8A8kLQ7GcPKWDk9jHzk/img.png|CDM|1.3|{\"originWidth\":523,\"originHeight\":297,\"style\":\"alignCenter\"}_##]\n",
    "-   다층 퍼셉트론\n",
    "    -   입력층과 출력층 사이에 하나 이상의 은닉층을 두어 비선형적으로 분리되는 데이터에 대해 학습이 가능한 퍼셉트론\n",
    "    -   역전파 알고리즘을 통해 다층으로 만들어진 퍼셉트론의 학습이 가능\n",
    "    -   활성화 함수로 시그모이드 함수 이용\n",
    "    -   문제점\n",
    "        -   과대 적합 : 학습 데이터 부족으로 인한 과적합 문제 발생\n",
    "        -   기울기 소실 : 시그이드 함수의 편미분은 진행할수록 0에 가까워지는 특성이 존재. RELU함수로 이를 해결\n",
    "-   다층 퍼셉트론 계산 과정(순전파)\n",
    "    -   은닉층이 1개이고, 입력 데이터의 개수는 4개($x\\_0$ 는 Bias Unit)\n",
    "\n",
    "$$a_1^{(2)} = g(\\Theta_{10}^{(1)}x_0 + \\Theta_{11}^{(1)}x_1 + \\Theta_{12}^{(1)}x_2 + \\Theta_{13}^{(1)}x_3)$$  \n",
    "$$a_2^{(2)} = g(\\Theta_{20}^{(1)}x_0 + \\Theta_{21}^{(1)}x_1 + \\Theta_{22}^{(1)}x_2 + \\Theta_{23}^{(1)}x_3)$$  \n",
    "$$a_3^{(2)} = g(\\Theta_{30}^{(1)}x_0 + \\Theta_{31}^{(1)}x_1 + \\Theta_{32}^{(1)}x_2 + \\Theta_{33}^{(1)}x_3)$$  \n",
    "$$h_{\\Theta}(x) = a_1^{(3)} = g(\\Theta_{10}^{(2)}a_0 + \\Theta_{11}^{(2)}x_0 + \\Theta_{21}^{(2)}x_0 + \\Theta_{31}^{(2)}x_0)$$\n",
    "\n",
    "$$z^{(j+1)} = \\Theta^{(j)}a^{(j)}$$  \n",
    "$$h_{\\Theta}(x) = a^{(j+1)} = g(z^{(j+1)})$$\n",
    "\n",
    "4) 활성화 함수\n",
    "\n",
    "-   순 입력함수로부터 전달받은 값을 출력값으로 변환해 주는 함수\n",
    "-   계단함수 : 임곗값을 기준으로 활성화(y축 1) 또는 비활성화(y축 0)가 됨\n",
    "-   부호함수 : 임곗값을 기준으로 양의부호(+1) 또는 음의부호(-1)를 출력\n",
    "-   시그모이드 함수 : 로지스틱 회귀모형과 작동원리가 유사함, 기울기 소실의 원리\n",
    "-   tanh함수 : 하이퍼볼릭 탄젠트 함수\n",
    "-   ReLU(Recified Linear Unit) :\n",
    "    -   X값이 0보다 큰 경우 y값도 지속적으로 커짐\n",
    "    -   시그모이드 기울기 소실 문제를 해결\n",
    "    -   X가 0보다 적은 경우 기울기가 0이므로 뉴런이 죽을 수 있음\n",
    "-   Leaky ReLU : ReLU 함수의 뉴런이 죽는 현상을 방지함\n",
    "\n",
    "5) 인공신경망 학습\n",
    "\n",
    "-   순전파(Feed Forward Propagation)\n",
    "    -   입력층(Input Layer)에서 출력층(Output Layer)까지 정보가 전달되는 과정\n",
    "    -   입력층(Input Layer)에서 은닉층(Hidden Layer) 방향으로 이동하면서 각 입력값의 가중치를 곱한다\n",
    "    -   은닉층(Hidden Layer)에서는 가중치가 반영된 입력값의 합계를 활성화 함수로 계산하고 결괏값을 출력층(Output Layer)으로 전달\n",
    "-   손실 함수(Loss Function)\n",
    "    -   실젯값과 예측값의 차이를 비교하는 지표\n",
    "    -   평균 제곱 에러(MSE) : $MSE = \\frac{1}{n} \\sum_{i=1}^{n}(y_i - h\\_{\\Theta}(x_i))^2$\n",
    "    -   교차 엔트로피 오차(CEE) : $E = - \\sum_{i=1}^{n}(t_i log y_i)$\n",
    "-   경사 하강법(Gradient Descent)\n",
    "    -   기울기를 낮은 쪽으로 계속 이동시켜 최적의 매개변수를 찾는 기법\n",
    "    -   함수의 기울기를 구하고 경사의 절댓값이 낮은 쪽으로 계속 이동시켜 극값에 이를 때까지 반복시키는 기법\n",
    "    -   학습률(Learning Rate)는 갱신하는 양으로 초 매개변수임\n",
    "    -   경사 하강법은 좋은 학습률을 설정하지 않으면 전역 최소값(Global Maximum)이 아닌 지역 최소값(Local Maximum)에 수렴할 수 있음\n",
    "-   오차 역전파(Back Propagation)\n",
    "    -   계산 결과와 정답의 오차를 구하고 오차와 관련된 값들의 가중치를 수정하여 오차가 작아지는 방향으로 일정 횟수를 반복해서 수정하는 방법\n",
    "    -   오차 역전파 계산 방법 : [오차 역전파 계산](https://blog.naver.com/wjdtjrrb05/222262194193)\n",
    "\n",
    "6) 인공신경망 학습 절차\n",
    "\n",
    "-   미니 배치 학습\n",
    "    -   훈련 데이터 일부를 무작위로 추출하는 과정\n",
    "    -   미니 배치의 손실 함수(Loss Function)을 줄이는 것이 목표\n",
    "-   기울기 산출\n",
    "    -   미니배치의 손실 함수값을 줄이기 위해 각 가중치 매개변수의 기울기를 구하는 과정\n",
    "    -   순전파 -> 역전파 과정을 통해 기울기를 계산\n",
    "-   매개변수 갱신\n",
    "    -   가중치 매개변수를 기울기 방향으로 조금씩 갱신하는 과정\n",
    "    -   경사하강법 적용\n",
    "-   반복\n",
    "    -   최적값을 찾을 때까지 1~3 반복 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa424cdd",
   "metadata": {},
   "source": [
    "### 서포트 벡신 머신 \n",
    "\n",
    "1) 서포트 벡터 머신(Support Vector Machine; SVM)\n",
    "\n",
    "- 벡터 공간에서 학습 데이터 속한 2개의 그룹을 분류하는 선형 분리자를 찾는 기하학적 모델\n",
    "- 데이터를 분리하는 초평면(Hyperplane) 중에서 데이터들과 거리가 가장 먼 초평면을 선택하여 분리하는 지도 학습 기반의 이진 선형 분류 모델\n",
    "- 최대 마진을 가지는 비확률적 선형 판별 분석에 기초한 이진 분류기\n",
    "- 변수 속성간의 의존성은 고려하지 않으며(다중공선성 등) 모든 속성을 활용하는 기법이다 \n",
    "- 훈련 시간은 상대적으로 느리나, 정확성이 뛰어나며 다른 방법보다 과대 적합의 가능성이 낮은 모델 \n",
    "\n",
    "2) 서포트 벡터 머신 구성요소\n",
    "\n",
    "- 결정 경계(Decision Boundary) : 데이터 분류의 기준이 되는 경계 \n",
    "- 초평면(Hyperplane) : n 차원 공간의 n-1 차원 평면\n",
    "- 마진(Margin) : 결정 경계에서 서포트 벡터까지의 거리, 마진을 최대화 -> 최대 마진 \n",
    "- 서포트 벡터 : 학습 데이터 중에서 결정 경계와 가장 가까이에 있는 데이터들의 집합\n",
    "- 슬랙 변수(Slack Variables) : 완벽한 분리가 불가능할 때 선형적으로 분류를 위해 허용된 오차를 위한 변수(Soft Margin SVM)\n",
    "\n",
    "3) 서포트 벡터 머신 종류 \n",
    "\n",
    "- 하드 마진 SVM \n",
    "\t- 마진의 안쪽이나 바깥쪽에 절대로 잘못 분류된 오 분류를 허용하지 않는 SVM\n",
    "    - 노이즈로 인하여 최적의 결정 경계를 잘 못 구하거나 못 찾을 수 도 있음\n",
    "- 소프트 마진 SVM\n",
    "\t- 마진의 안쪽이나 바깥쪽에 절대로 잘못 분류된 오 분류를 허용하는 SVM\n",
    "    - 어느 정도 오류를 허용함으로써 과대 적합 방지 \n",
    "    \n",
    "4) 서포트 벡터 머신 적용 기준\n",
    "\n",
    "- 선형으로 분리 가능한 SVM\n",
    "\t- 최적의 결정 경계를 기준으로 1, -1로 구분하여 분류 모형으로 사용 \n",
    "- 선형으로 분리 불가능한 SVM\n",
    "\t- 저차원 공간을 고차원 공간으로 매핑할 경우에 발생하는 연산의 복잡성은 커널 트릭을 통하여 해결이 가능\n",
    "\n",
    "\n",
    "**커널 트릭(Kernel Trick)**  \n",
    "저차원에서 함수의 계산만으로 원하는 풀이가 가능한 커널 함수를 이용하여 고차원 공간으로 매핑할 경우에 증가하는 연산량의 문제를 해결하는 기법. \n",
    "2차원에서 분류할 수 없는 문제를 3차원으로 매핑하여 선형 분류하게 되는데, 내적 함수 k를 통해 각각의 매핑함수를 정의하지 않고 내적 함수만 정의함으로써 서포트 벡터 머신의 계산량을 줄일 수 있다. 맵핑 공간에서의 내적과 동등한 함수를 커널함수라고 한다. \n",
    "\n",
    "5) 커널 함수의 종류\n",
    "\n",
    "- 선형 커널 : 기본 유형의 커널, 1차원이고 계산이 빠름\n",
    "- 다항 커널 : 선형커널의 일반화된 공식, 효과성과 정확도 측면에서 떨어짐\n",
    "- 가우시안 커널 : 일반적으로 사용하며, 데이터에 대한 사전 지식이 없는 경우 활용\n",
    "- 가우시안 RBF : 비선형 데이터가 있는 경우에 일반적으로 활용됨\n",
    "- 시그모이드 커널 : 인공신경망에서 선호되는 커널 \n",
    "\n",
    "6) 서포트 벡터 머신 장/단점 \n",
    "\n",
    "- 장점\n",
    "\t- 서포트 벡터만을 사용하여 결정 경계를 생성하므로 데이터가 적을 때 효과적\n",
    "    - 전체 데이터 포인트와의 거리를 계산하지 않고 서포트 벡터와의 거리만을 계산하면 되기 때문에 연산량 최소화\n",
    "    - 정확성이 뛰어나며, 커널 트릭을 활용하여 비선형 모델 분류 가능 \n",
    "    - 다른 모형보다 과대 적합의 가능성이 낮고, 노이즈의 영향이 적음\n",
    "    \n",
    "- 단점 \n",
    "\t- 데이터 전처리 과정이 중요 \n",
    "    - 데이터 세트의 크기가 클 경우 모델링에 많은 시간이 소요됨\n",
    "    - 커널과 모델의 매개변수를 조절하기 위해 많은 테스트가 필요 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa645607",
   "metadata": {},
   "source": [
    "### 연관성 분석 \n",
    "\n",
    "1) 연관성 분석\n",
    "\n",
    "-   데이터 내부에 존재하는 항목 간의 상호 관계 혹은 종속 관계를 찾아내는 분석 기법\n",
    "-   데이터 간의 관계에서 조건과 반응을 연결하는 분석으로 장바구니 분석, 서열 분석 이라고도 함\n",
    "\n",
    "2) 연관성 분석 특징\n",
    "\n",
    "-   목적변수가 없어 분석 방향이나 목적이 없어도 적용 가능\n",
    "-   조건 반응으로 표현되어 결과를 쉽게 이해할 수 있음\n",
    "-   적절한 세분화로 인한 품목 결정이 장점이지만 너무 세분화된 품목은 의미 없는 결과를 도출\n",
    "-   교차 판매, 묶음 판매, 상품 진열, 거래 후 쿠폰 제공, 온라인 쇼핑의 상품 추천\n",
    "\n",
    "3) 연관성 분석 추천 지표\n",
    "\n",
    "-   지지도\n",
    "    -   전체 거래 중 항목 A와 B를 동시에 포함하는 거래의 비율\n",
    "    -   $P(A \\cap B) = \\frac{A와 B가 동시에 포함된 거래 수}{전체 거래 수}$\n",
    "-   신뢰도\n",
    "    -   A 상품을 샀을 때 B 상품을 살 조건부 확률에 대한 척도\n",
    "    -   $P(B|A) = \\frac{A와 B가 동시에 포함된 거래 수}{A를 포함하는 거래 수}$\n",
    "-   향상도\n",
    "    -   규칙이 우연에 의해 발생한 것인지를 판단하 위해 연관성의 정도를 측정하는 척도\n",
    "    -   $\\frac{신뢰도}{P(B)}$\n",
    "    -   향상도 = 1 -> 서로 독립적 관계\n",
    "    -   향상도 > 1 -> 양의 상관관계\n",
    "    -   향상도 < 1 -> 음의 상관관계\n",
    "\n",
    "4) 연관성 분석 알고즘\n",
    "\n",
    "-   아프리오리 알고리즘\n",
    "    -   가능한 모든 경우의 수를 탐색하는 방식을 개선하 위하여 데이터들의 발생빈도가 높은 것을 찾는 알고리즘\n",
    "    -   분석 대상이 되는 항목의 대상을 최소화하여 큰 지지도 값을 갖는 빈발 항목 집합에 대해서만 연관규칙을 계산하는 알고리즘\n",
    "    -   한 항목이 자주 발생하지 않는다면 이 항목을 포함하는 집합들도 자주 발생하지 않는다는 규칙을 적용\n",
    "    -   계산 방법\n",
    "        -   우선적으로 최소 지지도 경곗값을 정하고 후보항목 집합을 생성함\n",
    "        -   후보 항목 집합에서 최소 지지도 경계값을 넘는 빈발항목 집합을 찾는다\n",
    "-   FP-Growth 알고리즘\n",
    "    -   FP-Tree라는 구조를 통해 최소 지지도를 만족하는 빈발 아이템 집합을 추출하는 알고리즘\n",
    "    -   모든 후보 아이템 세트들에 대하여 반복적으로 계산하는 단점이 있는 아프리오리 알고리즘을 개선한 알고리즘\n",
    "    -   장점\n",
    "        -   Tree 구조기 때문에 아프리오리 알고리즘보다 계산 속도가 빠르고 DB에서 스캔하는 횟수도 적음\n",
    "    -   단점\n",
    "        -   아프리오리에 비해 설계하기 어렵고, 지지도 계산은 무조건 FP-Tree가 만들어져야 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f46c30c",
   "metadata": {},
   "source": [
    "### 군집 분석 \n",
    "\n",
    "1) 군집 분석(Cluster Analysis)\n",
    "\n",
    "-   여러 개의 변수값들로부터 유사성에만 기초하여 n개의 군집으로 집단화하여 집단의 특성을 분석하는 다변량 분석 기법\n",
    "-   레이블이 없는 데이터 세트의 요약정보를 추출하고, 요약 정보를 통해 전체 데이터 세트가 가지고 있는 특징을 발견\n",
    "\n",
    "2) 군집 분석의 가정\n",
    "\n",
    "-   군집 내에 속한 개체들의 특성은 동질적이고 서로 다른 군집에 속한 개체들 간의 특성은 이질적이다\n",
    "-   군집 내의 응집도는 최대화하고, 군집 간의 분리도는 최대화 함\n",
    "-   구조와 관계없이 개체 간 거리를 기준으로 분류함\n",
    "\n",
    "3) 군집 간의 거리 계산\n",
    "\n",
    "-   연속형 변수 거리\n",
    "    -   수학적 거리\n",
    "        -   유클리드 거리(Euclidian) : $ d(i,j) = \\sqrt{\\sum_{f=1}^{p}(x_{if} - x_{jf})^2}$\n",
    "        -   맨하탄 거리(Manhattan) : $ d(i,j) = \\sum_{f=1}^{p}|x_{if} - x_{jf})|$\n",
    "        -   민코프스티(Minkowskii) : $ d(i,j) = (\\sum_{f=1}^{p}(x_{if} - x_{jf})^m)^{1/m}$\n",
    "    -   통계적 거리\n",
    "        -   표준화 거리 : 변수의 측정 단위를 표준화한 거리\n",
    "        -   말할라노비스 거리 : 변수의 표준화와 함께 변수 간의 상관성을 동시에 고려한 통계적 거리\n",
    "-   명목형 변수 거리\n",
    "    -   단순 일치 계수 : $\\frac{매칭된 속성의 개수}{속성의 개수}$\n",
    "    -   자카드(Jarcard) 계수 : $ J(A, B) = \\frac{|A \\cap B|}{|A| + |B| - |A \\cap B|} $\n",
    "-   순서형 변수 거리\n",
    "    -   순위상관계수(Rank Correlation Coefficient) : 값에 순위를 매겨 그 순위에 대해 상관계수를 구하는 방법\n",
    "\n",
    "4) 계층적 군집 분석\n",
    "\n",
    "-   병합적 방법\n",
    "    -   작은 군집으로부터 시작하여 군집을 병합하는 방법\n",
    "    -   거리가 가까우면 유사성이 높음\n",
    "-   분할적 방법\n",
    "    -   큰 군집으로부터 출발하여 군집을 분리해 나가는 기법\n",
    "-   계통도\n",
    "    -   군집의 결과는 계통도 또는 덴드로그램의 형태로 결과가 주어지며 각 개체는 하나의 군집에만 속하게 된다\n",
    "    -   항목간 거리, 군집 간의 거리를 알 수 있고, 군집 내 항목 간 유사 정도를 파악함으로써 견고성을 해석 가능\n",
    "-   군집 간의 거리측정 방법\n",
    "    -   최단 연결법 : 두 군집 사이의 거리를 각 군집에서 하나씩 관측값을 뽑았을 때 나타날 수 있는 거리의 최솟값으로 측정해서 가장 유사성이 큰 군집으로 병합해 나가는 방법\n",
    "    -   최장 연결법 : 두 군집 사이의 거리를 각 군집에서 하나씩 관측값을 뽑았을 떄 나타날 수 있는 거리의 최댓값으로 측정하여 가장 유사성이 큰 군집으로 병합해 나가는 방법\n",
    "    -   중심 연결법 : 두 군집의 중심간의 거리를 측정, 군집 내 편차들의 제곱합을 고려하여 군집 간 정보 손실을 최소화하는 방향으로 군집을 형성\n",
    "    -   평균 연결법 : 모든 항목에 대한 거리 평균을 구하면서 가장 유사성이 큰 군집을 병합해 나가는 방법\n",
    "    -   와드 연결법 : 군집 내의 오차제곱합에 기초하여 군집을 수행하는 방법, 오차제곱합의 증가량이 최초가 되는 방향으로 군집을 형성\n",
    "\n",
    "5) 비계층적 군집 분석\n",
    "\n",
    "-   분할 기반 군집(K-means clustering)\n",
    "    -   데이터를 K개의 군집으로 묶는 알고리즘으로 K개 만큼 군집수를 초깃값으로 지정하고, 각 개체를 가까운 초깃값에 할당하여 군집을 형성하고 각 군집의 평균을 재계산하여 초깃값을 갱신하는 과정을 반복하여 K개의 최종군집을 형성\n",
    "    -   군집의 수(K)는 초매개변수로 미리 정해준다\n",
    "    -   K개의 초기 중심 값은 임의로 선택할 수 있으며 자료 중에서 임의로 설정 가능\n",
    "    -   절차\n",
    "        -   K개 객체 선택 : 초기 군집 중심으로 K개의 객체를 임의로 선택\n",
    "        -   할당 : 자료를 가장 가까운 군집 중심에 할당\n",
    "        -   중심 갱신 : 각 군집 내의 자료들의 평균을 계산하여 군집의 중심을 갱신\n",
    "        -   반복 : 군집 중심의 변화 거의 없을 때까지 반복\n",
    "    -   K값 선정 기법\n",
    "        -   엘보우(Elbow) 기법 : x축에 클러스터의 개수, y축에 SSE값을 두었을 때 기울기 완만한 부분을 선택\n",
    "        -   실루엣 기법 : 각 군집 간의 거리가 얼마나 분리되어 있는지를 나타내는 기법\n",
    "        -   덴드로그램\n",
    "-   분보 기반 군집(혼합 분포 군집)\n",
    "    -   K개의 모수적 모형의 가중합으로 표현되는 모집단 무형으로부터 나왔다는 가정하에서 자료로부 모수와 가중치를 추정\n",
    "    -   K개의 모형중 어느 모형으로부터 나왔을 확률이 높은지에 따라 군집의 분류가 이루어짐\n",
    "    -   확률분포를 도입하여 군집을 수행하고, 서로 다른 크기의 군집을 찾을 수 있음\n",
    "    -   가우시안 혼합 모델(GMM)\n",
    "        -   전체 데이의 확률분포가 K개의 가우안 분포의 선형결합으로 이루어졌음을 가정하고 각 분포에 속할 확률이 높은 데이터 간의 군집을 형성\n",
    "        -   K 개의 가우시안 분포 중에서 어디에 속하는 것이 최적인지 추정\n",
    "    -   EM알고리즘\n",
    "        -   E-단계에는 잠재변수 Z의 기대치를 계산\n",
    "        -   M-단계에ㄴ 잠재변수 Z의 기대치를 이용하여 매개변수 추정\n",
    "-   밀도 기반 군집(DUBSCAN)\n",
    "    -   DUBSCAN은 개체들의 밀도 계산을 기반으로 밀접하게 분포된 개체들끼리 그룹핑하는 알고리즘\n",
    "    -   군집 밀도에 따라서 군집을 서로 연결하기 때문에 기하학적 모양의 군집 분석이 가능\n",
    "    -   구성요소\n",
    "        -   중심점 : 주변 반경 내에 최소 데이터 개수 이상의 다른 데이터를 가지고 있는 데이터\n",
    "        -   이웃점 : 특정 데이터 주변 반경 내에 존재하는 다른 데이터\n",
    "        -   경계점 : 중심점은 아니지만, 중심점이 주변 반경내에 존재하는 데이터\n",
    "        -   잡음점 : 중심점도 아니고 경계점 조건도 만족하지 못하는 이웃점\n",
    "    -   절차\n",
    "        -   반경 내에 최소 점 이상이 존재도록 중심점을 식별한다\n",
    "        -   인접 그래프에서 중심점과 연결된 구성요소를 찾는다\n",
    "        -   종심점 외에 속하면 노이즈로 할당한다\n",
    "    -   장점\n",
    "        -   K-means 과 같이 클러스터의 수를 정하지 않아도 됨\n",
    "        -   클러스터의 밀도에 따라서 클러스터를 서로 연결하 때문에 기하학적인 모양을 갖는 군집을 발견 가능\n",
    "    -   단점\n",
    "        -   초매개변수를 설정하기 어려움\n",
    "        -   다양한 밀도를 가지거나, 차원이 크면 계산에 어려움이 존재\n",
    "-   그래프 기반 군집(SOM)\n",
    "    -   인공신경망의 자율학습방법에 의한 클러스터링 방법을 적용한 알고리즘\n",
    "    -   고차원의 데이터를 이해하기 쉬운 저차원의 뉴런으로 정렬하여 지도의 형태로 형상화한 비지도 신경망\n",
    "    -   입력층과 경쟁층으로 구성된다\n",
    "\n",
    "6) 군집분석의 활용\n",
    "\n",
    "-   세분화\n",
    "-   이상탐지\n",
    "-   분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc02ba7",
   "metadata": {},
   "source": [
    "## 고급 분석 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e60c7",
   "metadata": {},
   "source": [
    "### 범주형 자료 분석 \n",
    "1) 범주형 자료 분석\n",
    "\n",
    "- 독립변수와 종속변수가 모두 범주형 데이터이거나 둘 중 하나가 범주형 데이터일 때 사용하는 분석 방법\n",
    "\n",
    "2) 분할표 분석(Contigency Table)\n",
    "\n",
    "- 분할표를 이용한 범주형 자료 분석은 상대 위험도와 승산비를 이용하여 분석한다 \n",
    "- 범주형 자료의 개수에 따라 One-way, Two-way, Multi-way 분할표로 나눌 수 있음\n",
    "- 상대 위험도(Relative Risk; RR)\n",
    "\t- 관심 집단의 위험률과 비교 집단의 위험률에 대한 비\n",
    "    - $상대위험도(RR) = \\frac{관심 집단의 발생확률}{비교 집단의 발생확률}$\n",
    "    - RR < 1 : 관십 집단의 특정 사건 발생 확률이 낮다고 평가\n",
    "    - RR = 1 : 관심 집단과 특정 사건의 발생에는 연관성이 없다고 평가\n",
    "    - RR > 1 : 관심 집단과 특정 사건의 발생 확률이 높다고 평가\n",
    "- 승산비(Odds Ratio) \n",
    "\t- 특정 조건이 있을 때의 성공 승산을 다른 조건이 있을 때의 성공 승산으로 나눈 값 \n",
    "    \n",
    "3) 카이제곱 검정 분석(Chi-Squared Test) \n",
    "\n",
    "- 카이제곱은 편차의 제곱 값을 기대빈도로 나눈 값들의 합이다\n",
    "- 범주형 자료 간의 차이를 보여주는 분석 방법으로 관찰된 빈도가 기대되는 빈도와 유의하 다른의 여부를 검정 \n",
    "\n",
    "- 적합도 검정\n",
    "\t- 변수가 1개이고 그 변수가 2개이상의 범주로 구성되어 있을 때 사용하는 일변량 분석 방법\n",
    "    - 표본 집단의 분포가 주어진 특정 분포를 따르고 있는지를 검정 \n",
    "    - 귀무가설 : '표본 집단의 분포가 주어진 특정 분포를 따른다' \n",
    "- 독립성 검정\n",
    "\t- 변수가 두개 이상의 범주로 분할되어 있을때 사용되며, 각 범주가 서로 독립적인지, 서로 연관성이 있는지를 검정하는 기법\n",
    "    - 귀무가설 : '요인1과 요인2는 독립적이다'\n",
    "- 동질성 검정 \n",
    "\t- 각각의 독립적인 부모집단으로부터 정해진 표본의 크기만큼 자료를 추출는 경우에 관측값들이 정해진 범주 내에서 서로 동질한지 여부를 검정하는 기법\n",
    "    - 귀무가설 : '모집단은 동질하다' \n",
    "\n",
    "4) 피셔의 정확 검정\n",
    "\n",
    "5) T-검정 \n",
    "\n",
    "- 독립변수가 범주형이고, 종속변수가 수치형일 때 두 집단의 평균을 비교하는 검정 방법 \n",
    "- 단일표본 T-검정\n",
    "\t- 한 집단의 평균이 모집단의 평균과 같은지 검정하는 방법\n",
    "    - 모집단의 평균이 알려져 있는 경우 하나의 표본 집단의 평균을 구하고 모집단의 평균과 표본 집단의 평균이 같은지를 검정\n",
    "- 대응표본 T-검정\n",
    "\t- 동일한 집단의 처치 전후 차이를 알아보기 위해 사용하는 검정 방법\n",
    "- 독립표본 T-검정 \n",
    "\t- 서로 다른 모집단에서 추출된 경우 사용할 수 있는 분석 방법\n",
    "    - 독립된 두 집단의 평균 차이를 검정하는 방법\n",
    "    - 정규성, 등분산성 가정이 만족되는지 먼저 확인 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28cc513",
   "metadata": {},
   "source": [
    "### 다변량 분석 \n",
    "\n",
    "1) 다변량 분석 \n",
    "- 여러 현상이나 사건에 대한 측정치를 개별적으로 분석하지 않고 동시에 분석하는 통계적 기법\n",
    "- 여러 변수 간의 관계성을 고려 \n",
    "\n",
    "2) 유형 \n",
    "- 분산 분석(ANOVA) : 하나의 종속변수와 하나 이상의 독립변수 간 관련성이 있다고 가정되는 문제에 적합한 기법\n",
    "- 다변량 분산 분석(MANOVA) : 두 개 이상의 종속변수와 다수의 독립변수 간의 관련성을 동시에 알아볼 때 적합한 기법\n",
    "- 판별 분석 : 분류된 집단 간의 차이를 설명해 줄 수 있는 독립변수들로 이루어진 최적판별식을 찾기 위한 기법\n",
    "- 다차원 척도법(MDS) : 개체들 사이의 유사성, 비유사성을 측정하여 2차원 또는 3차원 공간상에 점으로 표현하여 개체들 사이의 집단화를 시각적으로 표현하는 분석 기법\n",
    "- 군집분석 : 관측된 여러 개의 변수값들로부터 유사성에만 기초하여 n개의 군집으로 집단화하여 집단의 특성을 분석\n",
    "- 주성분 분석(PCA) : 상관관계가 있는 고차원의 자료를 자료의 변동을 최대한 보존하는 저차원 자료로 변환하는 차원축소 방법\n",
    "\n",
    "3) 다차원 척도법(MDS)\n",
    "- 개체들 사이의 유사성, 비유사성을 측정하여 2차원 또는 3차원 공간상에 점으로 표현하여 개체들 사이의 집단화를 시각적으로 표현하는 분석기법 \n",
    "- 개체들의 거리는 유클리드 거리행렬을 이용한다\n",
    "- 스트레스 값을 이용하여 관측 대상들의 적합도 수준을 나타낸다 \n",
    "- 스트레스 값은 0에 가까울수록 적합도 수준이 완벽하고 1에 가까울수록 나쁘다 \n",
    "- 종류\n",
    "\t- 계량적 다차원 척도법 \n",
    "    \t- 데이터가 연속형 변수인 경우 구간 척도나 비율 척도에 사용함 \n",
    "        - 유클리드 거리행렬을 이용하여 개체들 간의 실제거리를 계산하고 비유사성을 공간상에 표현 \n",
    "    - 비 계량적 다차원 척도법\n",
    "    \t- 데이터가 순서 척도인 경우에 사용\n",
    "        - 개체들 간의 절대적 거리는 무시하고 순서척도를 거리의 속성과 같도록 변환하여 거리를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf687e",
   "metadata": {},
   "source": [
    "### 주성분 분석 \n",
    "1) 주성분 분석(Principal Component Analysis; PCA)\n",
    "\n",
    "- 상관관계가 있는 고차원의 자료를 자료의 변동을 최대한 보존하는 저차원 자료로 변환하는 차원 축소 기법\n",
    "- 서로 상관성이 높은 변수들의 선형 결합으로 반들어 기존의 상관성이 높은 변수들을 요약, 축소하는 기법\n",
    "- 고윳값이 높은 순으로 정렬해서, 높은 고윳값을 가진 고유벡터만으로 데이터를 분석\n",
    "\n",
    "2) 주성분 분석의 특징\n",
    "\n",
    "- 누적 기여율이 85% 이상이면 주성분의 수로 결정함\n",
    "- 차원의 저주에 대한 접근 방법\n",
    "- 차원축소와 다중공선성 해결을 목적으로 함\n",
    "\n",
    "3) 주성분 분석 절차\n",
    "\n",
    "- 가장 큰 데이터 변동성을 기반으로 첫 번째 벡터 축 생성\n",
    "- 벡터 축에 직각이 되는 직교 벡터를 축으로 두 분째 벡터 축 생성\n",
    "- 앞의 단계와 동일한 방법으로 k 번째 벡터 축 생성\n",
    "- 벡터 축의 개수만큼 차원으로 원본 데이터를 차원 축소\n",
    "\n",
    "4) 주성분 개수 선택 방법\n",
    "\n",
    "- 누적 기여율(Cumulative Proportion)\n",
    "    - 누적 기여율은 제1 주성분부터 해당 주성분까지 분산 기여율의 합\n",
    "    - 누적 기여율이 85% 이상인 지점까지를 주성분의 수로 결정함\n",
    "- 스크리 산점도(Scree plot)\n",
    "    - 기울기가 완만해지기 직전까지를 주성분의 수로 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae7c658",
   "metadata": {},
   "source": [
    "### 시계열 분석\n",
    "1) 시계열 분석(Time-series Data)\n",
    "\n",
    "시계열 분석은 연도별, 분기별, 월별 등 시계열로 관측되는 자료를 분석하여 미래를 예측하기 위한 분석 기법\n",
    "\n",
    "\n",
    "2) 정상성(Stationary)\n",
    "\n",
    "시점에 상관없이 시계열의 특성이 일정하다는 의미\n",
    "\n",
    "- 평균이 일정하다\n",
    "- 분산이 시점에 의존하지 않는다\n",
    "- 공분산은 단지 시차에만 의존하고 시점 자체에는 의존하지 않는다\n",
    "\n",
    "3) 시계열 모형\n",
    "\n",
    "- 자기 회귀 모형(AR)\n",
    "    - 현시점의 자료가 p 시점 전의 유한개의 과거 자료로 설명될 수 있는 모형\n",
    "- 이동 평균 모형(MA)\n",
    "    - 시간이 지날수록 관측치의 평균값이 지속적으로 증가하거나 감소하는 시계열 모형\n",
    "    - 과거의 몇 개의 관측치를 평균하여 전반적인 추세를 파악할 수 있는 방법\n",
    "    - 현시점의 자료를 유한개의 백색잡음의 선형결합으로 표현하여 정상성 유지\n",
    "- 자기 회귀 누적 이동평균 모형(ARIMA)\n",
    "    - 분기/반기/연간 단위로 다음 지표를 예측하거나 주간/월간 단위로 지표를 리뷰하여 트랜드를 분석하는 기법\n",
    "    - 차분이나 변환을 통해 AR모형, MA모형, ARMA모형으로 정상화 할 수 있음\n",
    "    - 모형 차수\n",
    "        - p : AR모형과 관련\n",
    "        - q : MA모형과 관련\n",
    "        - d : ARMA로 정상화 할 때 몇 번 차분했는지 의미\n",
    "    - ARIMA(p, d, q) 의 조건\n",
    "        - p = 0 : IMA(d, q) 모형으로, d번 차분시 MA(q)가 된다\n",
    "        - q = 0 : AR(p, d) 모형으로, d번 차분시 AR(p)가 된다\n",
    "        - d = 0 : ARMA(p, q) 모형\n",
    "\n",
    "4) 시계열 분해\n",
    "\n",
    "- 시계열에 영향을 주는 일반적인 요인을 시계열에서 분리해 분석하는 방법\n",
    "- 구성요소\n",
    "    - 추세요인(Trend factor) : 자료가 어떤 특정한 형태를 취함\n",
    "    - 계절요인(Seasonal factor) : 고정된 주기에 따라 자료가 변함\n",
    "    - 순환요인(Cyclical factor) : 알려지지 않은 주기를 가지고 자료가 변함\n",
    "    - 불규칙요인(Irregular factor) : 추세, 계절, 순환 요인으로 설명할 수 없는 잔차에 해당하는 요인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5ff5d",
   "metadata": {},
   "source": [
    "### 딥러닝 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15738a24",
   "metadata": {},
   "source": [
    "1) 딥러닝 분석(Deep Learning)\n",
    "\n",
    "- 여러 비선형 변환 기법의 조합을 통해 높은 수준의 추상화를 시도하는 기계학습 알고리즘의 집합\n",
    "\n",
    "\n",
    "2) 딥러닝 특징\n",
    "\n",
    "- ReLU 함수를 이용한 기울기 소실 문제 해결\n",
    "- GPU를 활용하여 분석시간을 단축 시킴\n",
    "- 오차 역전파 사용\n",
    "- 은닉층을 사용하여 결과에 대한 해석이 어려움(BlackBox)\n",
    "- Dropout을 이용(무작위로 신경망의 뉴런을 제거하여 Overfitting을 방지)\n",
    "\n",
    "3) 딥러닝 알고리즘\n",
    "\n",
    "- DNN(Deep Neural Network)\n",
    "    - 은닉층을 심층 구성한 신경망으로 학습하는 알고리즘\n",
    "    - 순전파와 역전파를 동시에 사용하여 최적화된 가중치를 학습함\n",
    "- CNN(Convolution Neural Network)\n",
    "    - 시각적 이미지를 분석하는 데 사용되는 심층신경망으로 합성공 신경망으로 불림\n",
    "    - 순서\n",
    "        - 입력층 합성곱 연산 : 이미지에서 필터를 이용하여 특징을 추출한 피처맵을 구성\n",
    "        - 피처 맵에서 서브샘플링 연산 : 화면의 크기를 줄임(Max pool, Min pool)\n",
    "        - 피처 맵에서 합성곱, 서브샘플링을 반복 연산\n",
    "        - 완전연결계층에서 다층 신경망을 이용하여 분류 수행 : 2차원의 이미지를 1차원 행렬로 변환 후 입력층에 입력, Softmax 함수를 이용하여 결과를 확률로 분류\n",
    "    - CNN Feature Map\n",
    "        - 원본이미지의 크기가 n * n, 스트라이드가 s, 패딩이 p, 필터가 f * f 일 때,\n",
    "        - $Feature Map = (\\frac{n + 2p + f}{s} + 1) \\times (\\frac{n + 2p - f}{s} + 1)$\n",
    "- RNN(Recurrent Neural Network)\n",
    "    - 은닉층에서 재귀적인 신경망을 갖는 알고리즘\n",
    "    - 음성신호, 연속 시계열 데이터 분석에 적합\n",
    "\n",
    "**확률적 경사 하강법(Stochastic Gradient Descent; SGD)**  \n",
    "\n",
    "손실 함수의 기울기를 구하여, 그 기울기를 따라 조금씩 아래로 내려가 최종적으로는 손실 함수가 가장 작은 지점에 도달하도록 하는 알고리즘\n",
    "\n",
    "**시간 기반 오차 역전파**  \n",
    "\n",
    "역전파 알고리즘을 사용하여 모든 네트워크 매개변수와 관련하여 비용의 기울기를 찾는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885dda97",
   "metadata": {},
   "source": [
    "### 비정형 데이터 분석 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200ba68",
   "metadata": {},
   "source": [
    "1) 비정형 데이터 분석\n",
    "체계적인 통계적 규칙이나 패턴을 탐색하고 이를 의미있는 정보로 변환함으로써 기업의 의사결정에 적용하는 분석 기법\n",
    "\n",
    "\n",
    "2) 텍스트 마이닝\n",
    "\n",
    "- 텍스트 형태로 이루어진 비정형 데이터들을 자연어 처리 방식을 이용해 정보를 추출하는 기법\n",
    "- 절차\n",
    "    - 텍스트 수집 : 데이터 베이스, 텍스트 기반 문서 수집\n",
    "    - 데이터 전처리 : HTML 태그, XML 문법 제거, 문장 토큰화 / 파싱\n",
    "    - 의미 추출\n",
    "    - 패턴 분석\n",
    "    - 정보 생성\n",
    "- 기능\n",
    "    - 정보 추출 : 텍스트 문서로부터 사용자가 원하는 정보를 추출\n",
    "    - 문서 요약 : 문서에서 다룬 중요 내용을 글로 요약\n",
    "    - 문서 분류 : 키워드에 따라 문서를 분류\n",
    "    - 문서 군집화 : 동일 내용의 문서들을 묶음\n",
    "\n",
    "2) 오피니언 마이닝\n",
    "\n",
    "- 주관적인 의견이 포함된 데이터에서 사용자가 제개한 의견과 감정을 나타내는 패턴을 분석하는 기법\n",
    "- 절차\n",
    "    - 특징 추출 : 긍정 및 부정표현 단어 추출\n",
    "    - 문장 인식 : 오피니언으로 구성된 문장 인식\n",
    "    - 요약 및 전달 : 긍정, 부정 표현의 통계, 주요 문장을 추출하여 요약\n",
    "\n",
    "3) 웹 마이닝\n",
    "\n",
    "- 웹상의 문서들과 서비스들로부터 정보를 자동으로 추출, 발견하는 기법\n",
    "- 유형\n",
    "    - 웹 내용 마이닝 : 페이지의 내용 중에서 유용한 정보를 추출\n",
    "    - 웹 사용 마이닝 : 웹 로그를 통해 사용자의 패턴 분석\n",
    "    - 웹 구조 마이닝 : 구조적인 요약 정보를 찾기 위한 기법\n",
    "\n",
    "4) 사회 연결망 분석(SNA)\n",
    "\n",
    "- 개인과 집단 간의 관계를 노드와 링크로 그룹에 속한 사람들 간의 네트워크 특성과 구조를 분석하고 시각화 하는 분석 기법\n",
    "- 주요 속성\n",
    "    - 응집력 : 행위자들 간 강한 사회화 관계 존재\n",
    "    - 구조적 등위성 : 구조적 지위와 그 위치가 주는 역할이 동일한 사람들 간의 관계\n",
    "    - 명성 : 누가 권력을 가지고 있는지 확인\n",
    "    - 범위 : 행위자의 네트워크 규모\n",
    "    - 중계 : 다른 네트워크와 연결해주는 정도\n",
    "- 측정 지표\n",
    "    - 연결 정도 : 노드 간의 총 연결 관계 개수\n",
    "    - 포괄성 : 네트워크 내에서 서로 연결된 노드의 개수\n",
    "    - 밀도 : 네트워크 내에서 전반적인 연결 정도 수준\n",
    "    - 연결 정도 중심성 : 특정 노드가 연결망 내에서 연결된 노드의 합\n",
    "    - 근접 중심성 : 각 노드 간의 거리를 바탕으로 중심성을 측정\n",
    "    - 매개 중심성 : 네트워크 내에서 특정 노드가 다른 노드들 사이에 위치하는 정도\n",
    "    - 위세 중심성 : 자신의 연결정도 중심성으로부터 발생하는 영항력과 자신과 연결된 타인의 영향력을 합하여 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226ec9a",
   "metadata": {},
   "source": [
    "### 앙상블 분석 \n",
    "\n",
    "1) 앙상블(Ensemble) 분석\n",
    "\n",
    "여러 가지 동일한 종류 또는 서로 상이한 모형들의 예측/분류 결과를 종합하여 최종적인 의사결정에 활용하는 기법\n",
    "\n",
    "\n",
    "2) 앙상블 분석 종류\n",
    "\n",
    "- 배깅(Bagging, Bootstrap Aggregating)\n",
    "    - 학습 데이터에서 다수의 부트스트랩(Bootstrap) 자료를 생성하고, 각 자료를 모델링한 후 결합하여 최종 예측 모형을 만든다\n",
    "    - 부트스트랩(Bootstrap) : 주어진 자료에서 단순 랜덤 복원추출 방법을 활용하여 동일한 크기의 표본을 여러 개 생성하는 샘플링 기법\n",
    "    - 산출된 결과를 다수결에 의해서 최종 결과를 선정하는 과정\n",
    "    - 전반적으로 분류를 잘할 수 있도록 유도(분산 감소)\n",
    "    - 일반적으로 성능 향상에 효과적\n",
    "    - 소량의 데이터일수록 유리\n",
    "    - 주요 알고리즘 : 랜덤 포레스트 \n",
    "- 부스팅(Boosting)\n",
    "    - 잘못 분류된 개체들에 가중치를 적용, 새로운 분류 규칙을 만들고, 이 과정을 반복하여 최종 모형 생성\n",
    "    - 예측력이 약한 모형 들을 결합하여 강한 예측 모형을 만드는 방법\n",
    "    - 분류하기 힘든 관측값들에 대해서 정확하게 분류를 잘하도록 유도(예측력 강화)\n",
    "    - 순차 수행에 따른 가중치 재조정으로 결정\n",
    "    - 오 분류 데이터에는 높은 가중치 부여\n",
    "    - 속도가 느리고 과대적합 발생 가능성이 있음\n",
    "    - 주요 알고리즘 : AdaBoost, GBM(Gradient Boost Machine)\n",
    "- 랜덤 포레스트(Random Forest)\n",
    "    - 의사결정나무의 특징인 분산이 크다는 점을 고려하여 배깅과 부스팅보다 더 많은 무작위성을 부여하여 약한 학습기들을 생성후 선형결합하여 최종 학습기 생성\n",
    "    - 다수의 나무들로부터 투표를 통해 분류 결과를 도출\n",
    "    - 트리의 개수가 많을수록 과대적합 문제를 피할 수 있음\n",
    "    - 포레스트 크기, 최대 허용 깊이, 임의성 정도의 초 매개변수가 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c148b2",
   "metadata": {},
   "source": [
    "### 비모수 통계 \n",
    "1) 비모수 통계\n",
    "\n",
    "- 평균이나 분산 같은 모집단의 분포에 대한 모수성을 가정하지 않고 분석하는 통계적 방법\n",
    "- 이상값으로 인한 영향이 적음\n",
    "\n",
    "\n",
    "2) 검정 방법\n",
    "\n",
    "- 부호 검정(Sign Test)\n",
    "    - 차이의 크기는 무시하고 차이의 부호만을 이용한, 중위수의 위치에 대한 검정 방법 \n",
    "- 월콕슨 부호 순위 검정\n",
    "    - 중위수에 대한 검정에 사용되며, 대응되는 두 표본의 중위수의 차이 검정 방법 \n",
    "- 윌콕슨 순위 합 검정\n",
    "    - 두 표본의 혼합 표본에서 순위 합을 이용한 검정 방법 \n",
    "- 대응 표본 검정\n",
    "    - 하나의 모집단에서 두 가지 처리를 적용하여 관찰 값을 얻은 후 각 쌍의 차이를 이용하여 두 중위수의 차이를 검정\n",
    "- 크루스칼 왈리스 검정\n",
    "    - 세 집단 이상의 분포에 대한 중위수를 검정 \n",
    "- 런 검정\n",
    "    - 두 개의 값을 가지는 연속적인 측정값들이 어떤 패턴이나 경향이 없이 임의적으로 나타난 것인지를 검정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
