{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7feb51b",
   "metadata": {},
   "source": [
    "# 분석 모형 평가 및 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30842c",
   "metadata": {},
   "source": [
    "## 분석 모형 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492546de",
   "metadata": {},
   "source": [
    "### 평가지표 \n",
    "\n",
    "1) 분석 모형 설정 \n",
    "- 편향(Bias) : 학습 알고리즘에서 잘못된 가정을 했을 때 발생하는 오차\n",
    "- 분산(Variance) : 훈련 데이터에 내재된 작은 변동으로 발생하는 오차 \n",
    "- 낮은 평향과 낮은 분산으로 설정되어야 한다 \n",
    "\n",
    "2) 분석 모형 평가방법\n",
    "- 범주형 : 혼동 행렬(Confusion Matrix)\n",
    "- 연속형 : RMSE(Root Mean Squared Error) \n",
    "\n",
    "3) 회귀 모형 평가 지표\n",
    "- 오차 제곱합(SSE) : $SSE = \\sum_{i=1}^{n}(y_i - \\hat y_i)^2$\n",
    "- 전체 제곱합(SST) : $SST = \\sum_{i=1}^{n}(y_i - \\bar y_i)^2$\n",
    "- 회귀 제곱합(SSR) : $SSR = \\sum_{i=1}^{n}(\\hat y_i - \\bar y_i)^2$\n",
    "- 평균 오차(AE) : $AE = \\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat y_i)^2$\n",
    "- 평균 절대 오차(MAE) : $MAE = \\frac{1}{n} \\sum_{i=1}^{n}|y_i - \\hat y_i|^2$\n",
    "- 평균 제곱근 오차(RMSE) : $ RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(y_i - \\hat y_i)^2}$\n",
    "- 평균 절대 백분율 오차(MAPE) : $MAPE = \\frac{100}{n} \\sum_{i=1}^{n}|\\frac{y_i - \\hat y_i}{y_i}|$\n",
    "- 평균 백분율 오차(MPE) : $MPE = \\frac{100}{n} \\sum_{i=1}^{n}(\\frac{y_i - \\hat y_i}{y_i})$\n",
    "- 결정계수\n",
    "    - Coefficient of Determination($R^2$)\n",
    "    - 회귀 모형이 실제값을 얼마나 잘 나타내는지에 대한 비율 \n",
    "    - 1에 가까울 수록 잘 설명\n",
    "    - $R^2 = \\frac{SSR}{SST}$\n",
    "- 수정된 결정계수\n",
    "    - 적절하지 않는 독립변수를 추가하는 것에 패널티를 부가함\n",
    "    - $R_a ^ 2 = 1-(\\frac{n-1}{n-p-1})\\frac{SSE}{SST}$\n",
    "- Mallow's $C_p$\n",
    "    - 수정된 결정계수와 마찬가지로 적절하지 않는 독립변수에 패넡티를 부여 \n",
    "    - 값이 작을수록 설명력이 좋음 \n",
    "    \n",
    "4) 분석 모형 평가지표\n",
    "- 혼동 행렬(Confusion Matrix) \n",
    "    - 모델에서 구한 분류와 실제 분류를 교차표 형태로 정리한 행렬 \n",
    "    - 예측 클래스\n",
    "        - 예측이 정확한 경우 : TP, TN\n",
    "        - 예측이 부정확한 경우 : FP, FN \n",
    "    - 평가지표 \n",
    "        - 정확도(Accuracy) : $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "        - 오차비율(Error rate) : $\\frac{FP + FN}{TP + TN + FP + FN}$\n",
    "        - 재현율(Recall) : $\\frac{TP}{TP + FN}$\n",
    "        - 특이도(Specify) : $\\frac{TN}{TN + FP}$\n",
    "        - 거짓 긍정률 : $\\frac{FP}{TN + FP}$\n",
    "        - 정밀도(Precision) : $\\frac{TP}{TP + FP}$\n",
    "        - F-Measure : $2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$\n",
    "        - 카파 통계량(Kappa Statistics) : 두 관찰자가 측정한 범주 값에 대한 일치도를 측정하는 방법\n",
    "- ROC 곡선\n",
    "    - 가로축을 FP rate, 세로축을 TP rate로 두어 시각화한 그래프 \n",
    "    - 왼쪽 꼭대기에 가깝게 그려질수록 분류 성능이 우수 \n",
    "    - AUC(Area Under the ROC curve) : ROC곡선 아래의 면적을 모형의 평가지표로 설정\n",
    "    - AUC가 1에 가까울수록 좋음\n",
    "    \n",
    "- 이익 도표(Gain Chart) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441b845",
   "metadata": {},
   "source": [
    "### 분석 모형 진단 \n",
    "\n",
    "1) 분석 모형의 오류\n",
    "- 일반화 오류(Generalization Error) : 주어진 데이터 집합의 특성을 지나치게 반영하여 발생하는 오류, 과대적합 되었다고 함\n",
    "- 학습 오류(Training Error) : 데이터 집합의 특성을 덜 반영하도록 분석 모형을 만들어 생기는 오류, 과소적합 되었다고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9bfc98",
   "metadata": {},
   "source": [
    "### 교차 검증\n",
    "\n",
    "1) 교차 검증(Cross-Validation) : 모델의 일반화 오차에 대해 신뢰할 만한 추정치를 구하기 위해 훈련, 평가 데이터를 기반으로하는 검증 기법 \n",
    "\n",
    "2) 홀드 아웃 교차검증(Holdout Cross Validation) \n",
    "\n",
    "- 비복원 추출 방법을 이용하여 랜덤하게 훈련 데이터, 평가 데이터로 나눠 검증하는 기법\n",
    "- 계산량이 많지 않아 모형을 쉽게 평가할 수 있으나 전체 데이터에서 평가 데이터만큼은 학습에 사용할 수 없는 데이터 손실 발생\n",
    "- 데이터를 나누는 방법에 따라 결과가 달라짐 \n",
    "- trian_test_split()\n",
    "\n",
    "3) K-Fold Cross Validation\n",
    "\n",
    "- 데이터 집합을 무작위로 동일 크기를 갖는 K개의 부분 집합으로 나누고, 그 중 1개의 집합을 평가 데이터, 나머지 (K-1)개의 집합을 훈련 데이터로 선정하여 분석 모형을 평가\n",
    "- K값이 증가하면 수행 시간과 계산량도 많아짐\n",
    "- K에 다수결 또는 평균으로 분석 \n",
    "\n",
    "4) Leave-One-Out Cross Validation(LOOCV)\n",
    "\n",
    "- 전체 데이터 N개에서 1개의 샘플만을 평가 데이터에 사용하고 나머지 (N-1)개는 훈련 데이터로 사용하는 과정을 N번 반복\n",
    "- N-Fold Cross Validation과 방식이 같음 \n",
    "\n",
    "5) Leave-p-Out Cross Validation(LpOCV)\n",
    "\n",
    "- LOOCV에서 1개의 샘플이 아닌 p개의 샘플을 테스트에 사용하는 교차 검증 기법 \n",
    "\n",
    "6) 부트스트랩(Bootstrap) \n",
    "\n",
    "- 주어진 자료에서 단순 랜덤 복원추출 방법을 활용하여 동일한 크기의 표본을 여러 개 생성하는 샘플링 기법\n",
    "- 전체 데이터에서 중복을 허용하여 데이터 크기만큼 샘플을 추출함\n",
    "- 특정 샘플이 한 번도 선택되지 않는 경우는 36.8%\n",
    "- 한 번도 포함되지 않는 OOB 데이터는 검증에 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f05f09",
   "metadata": {},
   "source": [
    "### 모수 유의성 검정 \n",
    "\n",
    "1) 모수 유의성 검정 : 평균 및 분산에 따라 가설의 유의성 검정 \n",
    "\n",
    "2) 모집단의 평균에 대한 유의성 검정 \n",
    "\n",
    "- Z-검정 \n",
    "    - 검정 통계량의 분포를 정규분포로 근사할 수 있는 통계 검정\n",
    "    - 추출된 표본이 동일 모집단에 속하는지 가설검정\n",
    "    - 모집단 분산을 이미 알고 있을 경우 적용\n",
    "    \n",
    "- T-검정\n",
    "    - 귀무가설 하에서 T-분포를 따르는 통계적 가설 검정\n",
    "    - 모집단이 정규분포라는 정도만 알고 모분산을 모를 경우 적용\n",
    "    \n",
    "- 분산 분석(ANOVA)\n",
    "    - 두 개 이상의 집단 간 비교를 수행하고자 할 때 집단 내의 분산, 총 평균과 각 집단의 평균 차이에 의한 분산 비교로 얻은 F-분포를 사용하여 가설검정\n",
    "    - 일원배치 분산 분석 : 독립변수(1개) + 종속변수(1개)\n",
    "    - 이원배치 분산 분석 : 독립변수(2개) + 종속변수(1개) \n",
    "    - 다변량 분산 분석 : 독립변수(2개이상) + 종속변수(2개이상) \n",
    "    \n",
    "3) 모집단의 분산에 대한 유의성 검정\n",
    "\n",
    "- 카이제곱 검정 : 관찰된 빈도가 기대되는 빈도와 유의미하게 다른지 검정 \n",
    "- F-검정 : 두 표본의 분산에 대한 차이가 통계적으로 유의한지 검정, 모집단 분산 간의 비율에 대한 검정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c086c7a1",
   "metadata": {},
   "source": [
    "### 적합도 검정 \n",
    "\n",
    "1) 적합도 검정\n",
    "\n",
    "표본 집단의 분포가 주어진 특성 분포를 따르고 있는지 검정하는 기법 \n",
    "\n",
    "2) 정규성 검정\n",
    "\n",
    "- 샤피로-윌크 검정\n",
    "- 콜모고로프-스미르노프 적합성 검정 \n",
    "- Q-Q plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07c610",
   "metadata": {},
   "source": [
    "## 분석 모형 개선 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6dfe18",
   "metadata": {},
   "source": [
    "### 과대 적합 방지\n",
    "\n",
    "1) 과대 적합(Overfitting)\n",
    "\n",
    "훈련 데이터 세트가 지나치게 특화되어 새로운 데이터에 대한 오차가 매우 커지는 현상\n",
    " \n",
    "2) 과대 적합 방지\n",
    "\n",
    "- 데이터 증강(Data Augmentation) \n",
    "    - 훈련 데이터 세트 양이 적을 경우 충분한 데이터 세트를 확보\n",
    "    - 데이터를 변형해서 양을 늘릴 수 있음\n",
    "    \n",
    "- 모델의 복잡도 감소\n",
    "    - 은닉층의 수나 모델의 수용력 감소 \n",
    "    \n",
    "- 가중치 규제 적용 \n",
    "    - 개별 가중치 값을 제한하여 복잡한 모델을 좀 더 간단하게 하는 방법\n",
    "    - $\\lambda$가 크다면 매개변수를 제한하여 가중치를 크게 규제함 \n",
    "    - L1-norm(Lasso)\n",
    "        - 기존의 비용함수에 가중치의 절댓값의 합계를 추가하여 값이 최소가 되도록 함\n",
    "        - $\\lambda\\sum_{j=1}^{M}|w_j|$\n",
    "    - L2-norm(Ridge)\n",
    "        - 기존의 비용함수에 가중치의 제곱합의 합계를 추가함\n",
    "        - $\\lambda\\sum_{j=1}^{M}|w_j|^2$\n",
    "    - Elastic Net\n",
    "        - 기존 비용함수에 L1-norm, L2-norm규제를 추가함\n",
    "        - $\\alpha\\sum_{j=1}^{M}|w_j| + \\beta\\sum_{j=1}^{M}|w_j|^2$\n",
    "        \n",
    "- 드롭아웃(Dropout)\n",
    "    - 학습 과정에서 신경망 일부를 사용하지 않는 방법 \n",
    "    - 신경망 학습 시에만 활용하고 예측 시에는 활용하지 않는다\n",
    "    - 과대적합을 방지 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eb58cd",
   "metadata": {},
   "source": [
    "### 매개변수 최적화 \n",
    "\n",
    "1) 매개변수 최적화(Parameter Optimization)\n",
    "\n",
    "오차, 손실 함수의 값을 최대한 작게 하도록 하는 매개변수를 찾는 것 \n",
    "\n",
    "2) 매개변수 최적화 기법 \n",
    "\n",
    "- 확률적 경사 하강법(Stochatic Gradient Descent) \n",
    "    - 손실 함수의 기울기를 구하여 기울기를 따라 조금씩 아래로 내러가 손실 함수가 가장 작은 지점에 도달 \n",
    "    - 학습 1회에 밀요한 한 개의 데이터가 무작위로 선택 됨 \n",
    "    - 지역 극소점에 갇혀 전역 극소점을 찾지 못함 \n",
    "    - 최적점 근처에서 느리게 진행 \n",
    "    - 탐색경로가 지그재그임\n",
    "\n",
    "- 모멘텀\n",
    "    - 확률적 경사 하강법에 속도라는 개념을 추가함 \n",
    "    - 기울기가 줄어들더라도 빠르게 최적점으로 수렴 가능 \n",
    "    - 진동과 폭을 줄이며 속도가 빠름 \n",
    "    \n",
    "- AdaGrad(Adaptive Gradient Descent)\n",
    "    - 손실 함수의 기울기가 큰 첫 부분에는 크게 학습하다가, 최적점에 가까울수록 '학습률'을 줄여 적게 학습\n",
    "    - 각각의 매개변수에 맞는 학습률률 값을 설정 \n",
    "    - 최적점을 향해 매우 횽류적으로 움직임\n",
    "    \n",
    "- Adam(Adaptive Moment Estimation)\n",
    "    - 모멘텀 방식과 AdaGrid방식을 합친 알고리즘 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fa37f",
   "metadata": {},
   "source": [
    "### 분석 모형 융합 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea98b894",
   "metadata": {},
   "source": [
    "1) 취합(Aggregation)\n",
    "\n",
    "- 다수결 : 여러 모형에서 출력된 결과를 종합하여 다수결로 나온 모형을 최종 모형으로 선정\n",
    "- 배깅(Bagging) : 훈련 데이터의 중복을 허용하며 데이터 세트를 나누는 기법\n",
    "- 페이스팅(Pasting) : 훈련 데이터의 중복을 허용하지 않고 데이터 세트를 나누는 기법\n",
    "- 랜덤 서브스페이스 : 다차원 독립변수 중 일부 차원을 선택\n",
    "- 랜덤 패치 : 훈련 데이터와 독립변수 차원 모두 일부만 랜덤하게 사용 \n",
    "- 랜덤 포레스트 : 의사결정나무를 개별 모형으로 사용하는 모델 결합\n",
    "\n",
    "2) 부스팅(Boosting)\n",
    "\n",
    "- AdaBoost : 잘못 예측한 데이터에 가중치를 부여하여 오류를 개선하는 방식\n",
    "- Gradient Boost Machine : 경사 하강법을 이용하여 가중치 업데이트로 최적화된 결과를 얻는 알고리즘 \n",
    "\n",
    "-> Andrew NG 교수의 설명 방식과 유사 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23b60c",
   "metadata": {},
   "source": [
    "# 분석 결과 해석 및 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2c5ef",
   "metadata": {},
   "source": [
    "## 분석 결과 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dc7cf",
   "metadata": {},
   "source": [
    "### 시공간 시각화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8387f",
   "metadata": {},
   "source": [
    "### 분포 시각화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ba149",
   "metadata": {},
   "source": [
    "### 관계 시각화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1273cc",
   "metadata": {},
   "source": [
    "### 비교 시각화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ae547",
   "metadata": {},
   "source": [
    "### 인포그래픽"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2537d239",
   "metadata": {},
   "source": [
    "## 분석 결과 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3be725a",
   "metadata": {},
   "source": [
    "### 분석 모형 전개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118f219",
   "metadata": {},
   "source": [
    "### 분석 결과 활용 시나리오 개발 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f352c",
   "metadata": {},
   "source": [
    "### 분석 모형 모니터링 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fd65e",
   "metadata": {},
   "source": [
    "### 분석 모형 리모델링"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
