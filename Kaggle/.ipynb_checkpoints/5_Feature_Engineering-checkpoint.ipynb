{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50dda428",
   "metadata": {},
   "source": [
    "# What is Feature Engieering \n",
    "\n",
    "1. Learning What? :   \n",
    "\n",
    "- determine which features are the most important with mutual information.\n",
    "- invent new features in several real-world problem domains.\n",
    "- encode high-cardinalir categoriew with a target encoding. \n",
    "- create segmentation features with k-means clustering\n",
    "- decompose a dataset's variation into feature with principal component analysis.\n",
    "\n",
    "2. The Goal of Feature Engineering :  \n",
    "\n",
    "The goal of feature engineering is simply to make your data better suited to the problem at hand.  \n",
    "\n",
    "Consider \"apparent temperature\" measures like the heat index and the wind chill. These quantities attempt to measure the perceived temperature to humans based on air temperature, humidty, and wind speed, things which we can measure directly. You could think of an apparent temperature as the result of a kind of feature engieerning, an attemp to make the observed data more relevant to what we actually care about. \n",
    "\n",
    "- improve a model's predictive performance\n",
    "- reduce computational or data needs\n",
    "- improve interpretability of the results \n",
    "\n",
    "3. A Guiding Priciple of Feature Engineering :  \n",
    "\n",
    "For a feature to be useful, it must have a relationship to the target that your model is able to learn. Linear model, for instance, are only able to learn leiner relationship. So, when using a linear model, your goal is to transform the features to make their relationship to the target linear.  \n",
    "\n",
    "The key idea here is that a transformation you apply to a features becomes in essence a part of the model itself. Say you were trying to predict the Price of square plots of land from the Length of one side. Fitting a linear model directly ot Length gives poor results.   \n",
    "\n",
    "If we square the Length features to get \"Area\", however, we create a linear relationship. Adding Area to the feature set means this linear model can now fit a prarbola. Squaring a feature, in other words, gave the linear model the ability to fit squared features.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fcffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
