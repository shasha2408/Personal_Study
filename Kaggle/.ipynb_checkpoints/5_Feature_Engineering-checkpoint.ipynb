{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50dda428",
   "metadata": {},
   "source": [
    "# What is Feature Engieering \n",
    "\n",
    "1. Learning What? :   \n",
    "\n",
    "- determine which features are the most important with mutual information.\n",
    "- invent new features in several real-world problem domains.\n",
    "- encode high-cardinalir categoriew with a target encoding. \n",
    "- create segmentation features with k-means clustering\n",
    "- decompose a dataset's variation into feature with principal component analysis.\n",
    "\n",
    "2. The Goal of Feature Engineering :  \n",
    "\n",
    "The goal of feature engineering is simply to make your data better suited to the problem at hand.  \n",
    "\n",
    "Consider \"apparent temperature\" measures like the heat index and the wind chill. These quantities attempt to measure the perceived temperature to humans based on air temperature, humidty, and wind speed, things which we can measure directly. You could think of an apparent temperature as the result of a kind of feature engieerning, an attemp to make the observed data more relevant to what we actually care about. \n",
    "\n",
    "- improve a model's predictive performance\n",
    "- reduce computational or data needs\n",
    "- improve interpretability of the results \n",
    "\n",
    "3. A Guiding Priciple of Feature Engineering :  \n",
    "\n",
    "For a feature to be useful, it must have a relationship to the target that your model is able to learn. Linear model, for instance, are only able to learn leiner relationship. So, when using a linear model, your goal is to transform the features to make their relationship to the target linear.  \n",
    "\n",
    "The key idea here is that a transformation you apply to a features becomes in essence a part of the model itself. Say you were trying to predict the Price of square plots of land from the Length of one side. Fitting a linear model directly ot Length gives poor results.   \n",
    "\n",
    "If we square the Length features to get \"Area\", however, we create a linear relationship. Adding Area to the feature set means this linear model can now fit a prarbola. Squaring a feature, in other words, gave the linear model the ability to fit squared features.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e3120",
   "metadata": {},
   "source": [
    "4. Example - Concrete Formulations \n",
    "\n",
    "To illustrate these ideas we'll see how adding a few synthetic feqtures to a dataset can improve the predictive performance of a randomforest model.  \n",
    "\n",
    "The Concrete datasets contains a variety of concrete formulations and resulting products's compressive strength, which is a measure of how much load that kind of concrete cen bear. The task for dataset is to predict a concrete's compressive strength given its formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da179a4a",
   "metadata": {},
   "source": [
    "# Mutual Infromation\n",
    "\n",
    "First encountering a new datasets can sometimes feel overwhelming. ou might be preseneted with hundreds or thousands of features without even a description to go by. Where do you even begin?  \n",
    "\n",
    "A great first step is to construct a ranking with a feature utility metric, a function measuring associations between a feature and the target. Then you can choose a smaller set of the most useful feture and the target. Then you cna choose a smaller set of the most useful features to develop initally and have more confidence that your time will be well spent.  \n",
    "\n",
    "The metric we'll use is called \"mutual information\". Mutual information is a lot like correlation in that it mesures a relationship between two wuantities. The advantage of mututal information is that it can detect any kind of relationship, while correlation only detects linear relationships.  \n",
    "\n",
    "Mutual information is a great general-purpose metric and especially useful at the start of feature development when you might not know what model you'd like to use yet. It is : \n",
    "\n",
    "- easy to use and interpret,\n",
    "- computationally efficient,\n",
    "- theoretically well-founded,\n",
    "- resistant to overfitting, and, \n",
    "- able to detect any kind of relationship\n",
    "\n",
    "1. Mutual information and what it measures   \n",
    "\n",
    "Mutual information descirbes relationships in terms of uncertainty. The mutual information between two quantities is a meausre of the extent to which knowledge of one qulitiy reduces uncertainty aobut the other. If you knew the value of a feature, how much more confident would you be about the target?\n",
    "\n",
    "\n",
    "2. Interpreting Mutual information Scores\n",
    "\n",
    "The least possible mutual information between quantities is 0.0. When MI is zero, the quantities are independent : neither can tell you anything about the other. Coversly, in theroy there's no upper bound to what MI can be. In practice though values above 2.0 or so are uncommon. \n",
    "\n",
    "Here are some things to remember when applying mutual information : \n",
    "- MI can help you to understand the relative potential of a features as a predictor of the target, considered by itself. \n",
    "- If's possible for a feature to be very informative when interacting with other features, but not so informative all alone. MI can't detect interactiosn between features. It is a univariate metric.\n",
    "- The actural suefulness of a feature depends on the model you use it with. A feature is only useful to the extent that its relationship with the target is one your model can learn. Jsut becuase a feature has high MI score doesn't mean you model will be able to do anything with that information. you may need to transform the feature first toe expose the association\n",
    "\n",
    "**What need to focus**\n",
    "\n",
    "1. The scikit-learn algorithm for MI treats discrete features differently from continuous features. Consequently, you need to tell it which are which. As a rule of thumb, anything that must ahve a flaot dtypes is not discrete. Categorical can be treated by giving them a label encoding(or ordinaly encoding). \n",
    "\n",
    "2. Scikit-learn has two mutual information metrics in its feature_selection module: one for real-valued targets(mutaul_info_regresion) and one for categorical targets(mutual_info_classif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f46bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6cb54",
   "metadata": {},
   "source": [
    "Data visulaization is a great addition to your feature-engineering toolbox. Along with utility metrics like mutual information, visualization like these can help you discover important relationships in your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f642a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97a21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
